{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('save/conv_gan'):\n",
    "    os.mkdir('save/conv_gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    out = 0.5 * (x + 1)\n",
    "    out = out.clamp(0, 1)\n",
    "    out = out.reshape(-1, 1, 28, 28)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epoches = 100\n",
    "z_dimension = 100  # noise dimension\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") # whether GPU is supportted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST('../_data/mnist', transform=img_transform)\n",
    "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5, padding=2), # batch, 32, 28, 28\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.AvgPool2d(2, stride=2), # batch, 32, 14, 14\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 5, padding=2), # batch, 64, 14, 14\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.AvgPool2d(2, stride=2) # batch, 64, 7, 7\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 1024),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: batch, width, height, channel=1\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, input_size, num_feature):\n",
    "        super(generator, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_feature) # batch, 3136=1x56x56\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 50, 3, stride=1, padding=1), # batch, 50, 56, 56\n",
    "            nn.BatchNorm2d(50),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(50, 25, 3, stride=1, padding=1), # batch, 25, 56, 56\n",
    "            nn.BatchNorm2d(25),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(25, 1, 2, stride=2), # batch, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 1, 56, 56)\n",
    "        x = self.br(x)\n",
    "        x = self.downsample1(x)\n",
    "        x = self.downsample2(x)\n",
    "        x = self.downsample3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator().to(device) # discriminator model\n",
    "G = generator(z_dimension, 3136).to(device) # generator model\n",
    "\n",
    "criterion = nn.BCELoss()  # binary cross entropy\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], d_loss: 0.005740, g_loss: 8.382010 D real: 0.999600, D fake: 0.005291\n",
      "Epoch [1/100], d_loss: 0.120890, g_loss: 3.710974 D real: 0.941817, D fake: 0.044033\n",
      "Epoch [1/100], d_loss: 1.302253, g_loss: 0.627670 D real: 0.489692, D fake: 0.016980\n",
      "Epoch [1/100], d_loss: 0.694377, g_loss: 1.666312 D real: 0.793562, D fake: 0.295947\n",
      "Epoch [2/100], d_loss: 0.749656, g_loss: 1.458905 D real: 0.637752, D fake: 0.070408\n",
      "Epoch [2/100], d_loss: 0.448467, g_loss: 1.447083 D real: 0.805019, D fake: 0.153906\n",
      "Epoch [2/100], d_loss: 0.482298, g_loss: 3.548074 D real: 0.759879, D fake: 0.097495\n",
      "Epoch [2/100], d_loss: 0.441377, g_loss: 3.199620 D real: 0.818883, D fake: 0.144127\n",
      "Epoch [3/100], d_loss: 0.393238, g_loss: 3.646580 D real: 0.906582, D fake: 0.182718\n",
      "Epoch [3/100], d_loss: 0.340518, g_loss: 3.682391 D real: 0.876287, D fake: 0.134393\n",
      "Epoch [3/100], d_loss: 0.315354, g_loss: 3.013805 D real: 0.868112, D fake: 0.074906\n",
      "Epoch [3/100], d_loss: 0.279002, g_loss: 2.872003 D real: 0.912229, D fake: 0.101350\n",
      "Epoch [4/100], d_loss: 0.362514, g_loss: 3.195453 D real: 0.835265, D fake: 0.063899\n",
      "Epoch [4/100], d_loss: 0.325750, g_loss: 3.533022 D real: 0.896301, D fake: 0.125666\n",
      "Epoch [4/100], d_loss: 0.340938, g_loss: 4.042368 D real: 0.894505, D fake: 0.124798\n",
      "Epoch [4/100], d_loss: 0.314543, g_loss: 2.799916 D real: 0.887707, D fake: 0.118425\n",
      "Epoch [5/100], d_loss: 0.537166, g_loss: 2.700612 D real: 0.896191, D fake: 0.251923\n",
      "Epoch [5/100], d_loss: 0.340762, g_loss: 2.225832 D real: 0.881338, D fake: 0.126929\n",
      "Epoch [5/100], d_loss: 0.389182, g_loss: 1.971458 D real: 0.878000, D fake: 0.164512\n",
      "Epoch [5/100], d_loss: 0.487114, g_loss: 2.566824 D real: 0.832476, D fake: 0.148539\n",
      "Epoch [6/100], d_loss: 0.497645, g_loss: 1.536353 D real: 0.870001, D fake: 0.201233\n",
      "Epoch [6/100], d_loss: 0.624152, g_loss: 2.705030 D real: 0.729102, D fake: 0.029063\n",
      "Epoch [6/100], d_loss: 0.559466, g_loss: 2.805529 D real: 0.923914, D fake: 0.304613\n",
      "Epoch [6/100], d_loss: 0.389685, g_loss: 2.496176 D real: 0.864725, D fake: 0.128774\n",
      "Epoch [7/100], d_loss: 0.508086, g_loss: 3.155468 D real: 0.880208, D fake: 0.222864\n",
      "Epoch [7/100], d_loss: 0.531727, g_loss: 2.587862 D real: 0.764933, D fake: 0.084465\n",
      "Epoch [7/100], d_loss: 0.548894, g_loss: 2.092887 D real: 0.787963, D fake: 0.092407\n",
      "Epoch [7/100], d_loss: 0.478066, g_loss: 2.400919 D real: 0.853583, D fake: 0.169320\n",
      "Epoch [8/100], d_loss: 0.441386, g_loss: 3.267063 D real: 0.872796, D fake: 0.189105\n",
      "Epoch [8/100], d_loss: 0.439377, g_loss: 2.985277 D real: 0.889700, D fake: 0.212352\n",
      "Epoch [8/100], d_loss: 0.487770, g_loss: 2.954689 D real: 0.860161, D fake: 0.199796\n",
      "Epoch [8/100], d_loss: 0.416943, g_loss: 2.197428 D real: 0.866377, D fake: 0.165246\n",
      "Epoch [9/100], d_loss: 0.596322, g_loss: 1.972951 D real: 0.788622, D fake: 0.146038\n",
      "Epoch [9/100], d_loss: 0.609542, g_loss: 1.261721 D real: 0.782013, D fake: 0.160673\n",
      "Epoch [9/100], d_loss: 0.377755, g_loss: 1.876122 D real: 0.841349, D fake: 0.101419\n",
      "Epoch [9/100], d_loss: 0.493308, g_loss: 2.310487 D real: 0.830806, D fake: 0.159142\n",
      "Epoch [10/100], d_loss: 0.468571, g_loss: 2.467659 D real: 0.916145, D fake: 0.256967\n",
      "Epoch [10/100], d_loss: 0.467434, g_loss: 2.267820 D real: 0.818107, D fake: 0.130664\n",
      "Epoch [10/100], d_loss: 0.601041, g_loss: 2.097560 D real: 0.869843, D fake: 0.288058\n",
      "Epoch [10/100], d_loss: 0.464864, g_loss: 1.687162 D real: 0.814832, D fake: 0.120077\n",
      "Epoch [11/100], d_loss: 0.512119, g_loss: 2.448179 D real: 0.864277, D fake: 0.213469\n",
      "Epoch [11/100], d_loss: 0.504365, g_loss: 3.093728 D real: 0.861231, D fake: 0.204526\n",
      "Epoch [11/100], d_loss: 0.537562, g_loss: 3.522773 D real: 0.871402, D fake: 0.244030\n",
      "Epoch [11/100], d_loss: 0.457989, g_loss: 2.101030 D real: 0.887306, D fake: 0.213974\n",
      "Epoch [12/100], d_loss: 0.497948, g_loss: 2.785896 D real: 0.778058, D fake: 0.094188\n",
      "Epoch [12/100], d_loss: 0.602017, g_loss: 1.672163 D real: 0.880849, D fake: 0.294301\n",
      "Epoch [12/100], d_loss: 0.507582, g_loss: 2.720035 D real: 0.859843, D fake: 0.211319\n",
      "Epoch [12/100], d_loss: 0.476864, g_loss: 1.932875 D real: 0.881480, D fake: 0.234307\n",
      "Epoch [13/100], d_loss: 0.546027, g_loss: 2.023980 D real: 0.762524, D fake: 0.089220\n",
      "Epoch [13/100], d_loss: 0.549068, g_loss: 2.275115 D real: 0.817708, D fake: 0.168533\n",
      "Epoch [13/100], d_loss: 0.445386, g_loss: 2.816660 D real: 0.871131, D fake: 0.176673\n",
      "Epoch [13/100], d_loss: 0.621135, g_loss: 2.080251 D real: 0.780587, D fake: 0.134638\n",
      "Epoch [14/100], d_loss: 0.543385, g_loss: 2.254631 D real: 0.815970, D fake: 0.197304\n",
      "Epoch [14/100], d_loss: 0.582781, g_loss: 2.615671 D real: 0.758221, D fake: 0.132347\n",
      "Epoch [14/100], d_loss: 0.684690, g_loss: 1.933698 D real: 0.712786, D fake: 0.069625\n",
      "Epoch [14/100], d_loss: 0.545885, g_loss: 2.369545 D real: 0.782088, D fake: 0.132988\n",
      "Epoch [15/100], d_loss: 0.593168, g_loss: 1.490904 D real: 0.726897, D fake: 0.056951\n",
      "Epoch [15/100], d_loss: 0.517097, g_loss: 2.516309 D real: 0.797785, D fake: 0.152172\n",
      "Epoch [15/100], d_loss: 0.497407, g_loss: 2.290015 D real: 0.829056, D fake: 0.173362\n",
      "Epoch [15/100], d_loss: 0.560139, g_loss: 1.593628 D real: 0.871952, D fake: 0.258894\n",
      "Epoch [16/100], d_loss: 0.554035, g_loss: 2.414494 D real: 0.801398, D fake: 0.136921\n",
      "Epoch [16/100], d_loss: 0.519242, g_loss: 2.083070 D real: 0.874548, D fake: 0.251756\n",
      "Epoch [16/100], d_loss: 0.498188, g_loss: 2.717754 D real: 0.853603, D fake: 0.209488\n",
      "Epoch [16/100], d_loss: 0.705652, g_loss: 2.467789 D real: 0.775158, D fake: 0.215425\n",
      "Epoch [17/100], d_loss: 0.461272, g_loss: 2.670560 D real: 0.872823, D fake: 0.193919\n",
      "Epoch [17/100], d_loss: 0.608511, g_loss: 2.946855 D real: 0.764054, D fake: 0.129762\n",
      "Epoch [17/100], d_loss: 0.520113, g_loss: 1.674501 D real: 0.826731, D fake: 0.177537\n",
      "Epoch [17/100], d_loss: 0.598249, g_loss: 2.321769 D real: 0.841612, D fake: 0.221729\n",
      "Epoch [18/100], d_loss: 0.499914, g_loss: 3.865614 D real: 0.874326, D fake: 0.210867\n",
      "Epoch [18/100], d_loss: 0.516424, g_loss: 2.670893 D real: 0.878214, D fake: 0.227645\n",
      "Epoch [18/100], d_loss: 0.548198, g_loss: 2.661940 D real: 0.870059, D fake: 0.271230\n",
      "Epoch [18/100], d_loss: 0.473449, g_loss: 1.996944 D real: 0.823033, D fake: 0.110685\n",
      "Epoch [19/100], d_loss: 0.489489, g_loss: 2.420797 D real: 0.872590, D fake: 0.213438\n",
      "Epoch [19/100], d_loss: 0.606650, g_loss: 2.192120 D real: 0.825722, D fake: 0.215446\n",
      "Epoch [19/100], d_loss: 0.574527, g_loss: 2.349418 D real: 0.889772, D fake: 0.262802\n",
      "Epoch [19/100], d_loss: 0.546503, g_loss: 2.416409 D real: 0.879063, D fake: 0.236572\n",
      "Epoch [20/100], d_loss: 0.382546, g_loss: 1.767819 D real: 0.866702, D fake: 0.121218\n",
      "Epoch [20/100], d_loss: 0.530588, g_loss: 1.666976 D real: 0.763611, D fake: 0.112412\n",
      "Epoch [20/100], d_loss: 0.398130, g_loss: 2.555426 D real: 0.852437, D fake: 0.125522\n",
      "Epoch [20/100], d_loss: 0.635706, g_loss: 1.822781 D real: 0.800046, D fake: 0.178614\n",
      "Epoch [21/100], d_loss: 0.444636, g_loss: 1.616411 D real: 0.863913, D fake: 0.184733\n",
      "Epoch [21/100], d_loss: 0.452136, g_loss: 2.578408 D real: 0.816697, D fake: 0.131156\n",
      "Epoch [21/100], d_loss: 0.514164, g_loss: 2.113400 D real: 0.841846, D fake: 0.208809\n",
      "Epoch [21/100], d_loss: 0.555181, g_loss: 2.120085 D real: 0.870610, D fake: 0.261600\n",
      "Epoch [22/100], d_loss: 0.585504, g_loss: 3.135148 D real: 0.832376, D fake: 0.198068\n",
      "Epoch [22/100], d_loss: 0.570363, g_loss: 2.457551 D real: 0.864444, D fake: 0.235723\n",
      "Epoch [22/100], d_loss: 0.502429, g_loss: 2.411233 D real: 0.865095, D fake: 0.203793\n",
      "Epoch [22/100], d_loss: 0.516177, g_loss: 2.027638 D real: 0.804230, D fake: 0.119898\n",
      "Epoch [23/100], d_loss: 0.530237, g_loss: 2.025518 D real: 0.866337, D fake: 0.220995\n",
      "Epoch [23/100], d_loss: 0.564051, g_loss: 2.035559 D real: 0.759816, D fake: 0.133160\n",
      "Epoch [23/100], d_loss: 0.543362, g_loss: 2.063849 D real: 0.773946, D fake: 0.107357\n",
      "Epoch [23/100], d_loss: 0.557376, g_loss: 2.071812 D real: 0.823917, D fake: 0.174977\n",
      "Epoch [24/100], d_loss: 0.503613, g_loss: 3.204348 D real: 0.832470, D fake: 0.143543\n",
      "Epoch [24/100], d_loss: 0.482611, g_loss: 2.125209 D real: 0.792891, D fake: 0.079505\n",
      "Epoch [24/100], d_loss: 0.450201, g_loss: 2.544999 D real: 0.877097, D fake: 0.205261\n",
      "Epoch [24/100], d_loss: 0.606843, g_loss: 2.138517 D real: 0.864409, D fake: 0.250840\n",
      "Epoch [25/100], d_loss: 0.475775, g_loss: 2.520997 D real: 0.848360, D fake: 0.167383\n",
      "Epoch [25/100], d_loss: 0.614101, g_loss: 2.689898 D real: 0.785515, D fake: 0.164355\n",
      "Epoch [25/100], d_loss: 0.550230, g_loss: 2.591477 D real: 0.811291, D fake: 0.117183\n",
      "Epoch [25/100], d_loss: 0.536817, g_loss: 1.948257 D real: 0.778817, D fake: 0.095167\n",
      "Epoch [26/100], d_loss: 0.469499, g_loss: 3.142463 D real: 0.870309, D fake: 0.205667\n",
      "Epoch [26/100], d_loss: 0.571864, g_loss: 1.985623 D real: 0.818573, D fake: 0.204231\n",
      "Epoch [26/100], d_loss: 0.494949, g_loss: 2.561617 D real: 0.863052, D fake: 0.199082\n",
      "Epoch [26/100], d_loss: 0.543900, g_loss: 2.329353 D real: 0.816497, D fake: 0.163124\n",
      "Epoch [27/100], d_loss: 0.597282, g_loss: 2.417256 D real: 0.759982, D fake: 0.127896\n",
      "Epoch [27/100], d_loss: 0.600649, g_loss: 2.226139 D real: 0.871048, D fake: 0.270835\n",
      "Epoch [27/100], d_loss: 0.624371, g_loss: 2.659065 D real: 0.774455, D fake: 0.134929\n",
      "Epoch [27/100], d_loss: 0.499136, g_loss: 2.147740 D real: 0.816680, D fake: 0.152822\n",
      "Epoch [28/100], d_loss: 0.463028, g_loss: 2.785681 D real: 0.833798, D fake: 0.140605\n",
      "Epoch [28/100], d_loss: 0.540675, g_loss: 1.821593 D real: 0.865040, D fake: 0.218557\n",
      "Epoch [28/100], d_loss: 0.503857, g_loss: 2.663030 D real: 0.791360, D fake: 0.072618\n",
      "Epoch [28/100], d_loss: 0.556893, g_loss: 3.202543 D real: 0.823549, D fake: 0.153437\n",
      "Epoch [29/100], d_loss: 0.405777, g_loss: 2.286478 D real: 0.827745, D fake: 0.111554\n",
      "Epoch [29/100], d_loss: 0.441927, g_loss: 2.868749 D real: 0.818384, D fake: 0.068072\n",
      "Epoch [29/100], d_loss: 0.459726, g_loss: 2.432183 D real: 0.814662, D fake: 0.129507\n",
      "Epoch [29/100], d_loss: 0.589249, g_loss: 1.761208 D real: 0.768558, D fake: 0.112868\n",
      "Epoch [30/100], d_loss: 0.473361, g_loss: 1.994614 D real: 0.876628, D fake: 0.197773\n",
      "Epoch [30/100], d_loss: 0.460606, g_loss: 2.693320 D real: 0.854275, D fake: 0.173853\n",
      "Epoch [30/100], d_loss: 0.551531, g_loss: 1.929614 D real: 0.818513, D fake: 0.156196\n",
      "Epoch [30/100], d_loss: 0.417303, g_loss: 3.354942 D real: 0.895284, D fake: 0.169860\n",
      "Epoch [31/100], d_loss: 0.440555, g_loss: 2.670019 D real: 0.823772, D fake: 0.107281\n",
      "Epoch [31/100], d_loss: 0.448228, g_loss: 2.273784 D real: 0.833803, D fake: 0.132702\n",
      "Epoch [31/100], d_loss: 0.526525, g_loss: 2.108033 D real: 0.808811, D fake: 0.117579\n",
      "Epoch [31/100], d_loss: 0.664956, g_loss: 3.281619 D real: 0.857264, D fake: 0.232682\n",
      "Epoch [32/100], d_loss: 0.579323, g_loss: 2.764024 D real: 0.774469, D fake: 0.145194\n",
      "Epoch [32/100], d_loss: 0.610780, g_loss: 2.292315 D real: 0.759007, D fake: 0.124061\n",
      "Epoch [32/100], d_loss: 0.434236, g_loss: 2.268772 D real: 0.837203, D fake: 0.120112\n",
      "Epoch [32/100], d_loss: 0.456715, g_loss: 2.240836 D real: 0.917256, D fake: 0.241739\n",
      "Epoch [33/100], d_loss: 0.582787, g_loss: 2.399690 D real: 0.775702, D fake: 0.100386\n",
      "Epoch [33/100], d_loss: 0.493477, g_loss: 1.956627 D real: 0.857880, D fake: 0.166553\n",
      "Epoch [33/100], d_loss: 0.591155, g_loss: 3.141056 D real: 0.771995, D fake: 0.089545\n",
      "Epoch [33/100], d_loss: 0.523018, g_loss: 1.836496 D real: 0.814451, D fake: 0.150232\n",
      "Epoch [34/100], d_loss: 0.457741, g_loss: 2.708321 D real: 0.832365, D fake: 0.128685\n",
      "Epoch [34/100], d_loss: 0.566632, g_loss: 3.009092 D real: 0.798890, D fake: 0.146149\n",
      "Epoch [34/100], d_loss: 0.461254, g_loss: 1.761921 D real: 0.848780, D fake: 0.172008\n",
      "Epoch [34/100], d_loss: 0.551620, g_loss: 2.365355 D real: 0.847764, D fake: 0.207456\n",
      "Epoch [35/100], d_loss: 0.418607, g_loss: 2.640953 D real: 0.913212, D fake: 0.211642\n",
      "Epoch [35/100], d_loss: 0.427641, g_loss: 3.125395 D real: 0.862037, D fake: 0.129458\n",
      "Epoch [35/100], d_loss: 0.590303, g_loss: 2.493798 D real: 0.765659, D fake: 0.118230\n",
      "Epoch [35/100], d_loss: 0.528410, g_loss: 3.164969 D real: 0.771471, D fake: 0.073753\n",
      "Epoch [36/100], d_loss: 0.531558, g_loss: 3.327084 D real: 0.790719, D fake: 0.048895\n",
      "Epoch [36/100], d_loss: 0.400140, g_loss: 2.510949 D real: 0.875028, D fake: 0.131564\n",
      "Epoch [36/100], d_loss: 0.440977, g_loss: 2.791707 D real: 0.851805, D fake: 0.122584\n",
      "Epoch [36/100], d_loss: 0.613003, g_loss: 2.233932 D real: 0.929530, D fake: 0.337557\n",
      "Epoch [37/100], d_loss: 0.457639, g_loss: 1.930048 D real: 0.903131, D fake: 0.207873\n",
      "Epoch [37/100], d_loss: 0.341042, g_loss: 2.719643 D real: 0.936869, D fake: 0.193750\n",
      "Epoch [37/100], d_loss: 0.397383, g_loss: 2.798210 D real: 0.866128, D fake: 0.116863\n",
      "Epoch [37/100], d_loss: 0.486591, g_loss: 2.180344 D real: 0.838068, D fake: 0.161389\n",
      "Epoch [38/100], d_loss: 0.391329, g_loss: 2.910022 D real: 0.836173, D fake: 0.079916\n",
      "Epoch [38/100], d_loss: 0.507740, g_loss: 1.891908 D real: 0.834687, D fake: 0.151302\n",
      "Epoch [38/100], d_loss: 0.456512, g_loss: 2.108572 D real: 0.831893, D fake: 0.144168\n",
      "Epoch [38/100], d_loss: 0.511530, g_loss: 3.398795 D real: 0.818607, D fake: 0.089776\n",
      "Epoch [39/100], d_loss: 0.522534, g_loss: 2.016806 D real: 0.859783, D fake: 0.189980\n",
      "Epoch [39/100], d_loss: 0.516170, g_loss: 2.024280 D real: 0.900123, D fake: 0.250738\n",
      "Epoch [39/100], d_loss: 0.444263, g_loss: 2.233046 D real: 0.832222, D fake: 0.108195\n",
      "Epoch [39/100], d_loss: 0.414417, g_loss: 3.222105 D real: 0.890786, D fake: 0.166863\n",
      "Epoch [40/100], d_loss: 0.498878, g_loss: 3.253382 D real: 0.793310, D fake: 0.054756\n",
      "Epoch [40/100], d_loss: 0.362799, g_loss: 2.173345 D real: 0.882430, D fake: 0.132541\n",
      "Epoch [40/100], d_loss: 0.511650, g_loss: 2.873387 D real: 0.830753, D fake: 0.146461\n",
      "Epoch [40/100], d_loss: 0.454123, g_loss: 2.616627 D real: 0.838378, D fake: 0.114782\n",
      "Epoch [41/100], d_loss: 0.510066, g_loss: 3.216654 D real: 0.811270, D fake: 0.092593\n",
      "Epoch [41/100], d_loss: 0.538855, g_loss: 2.198821 D real: 0.873371, D fake: 0.217393\n",
      "Epoch [41/100], d_loss: 0.620882, g_loss: 2.189066 D real: 0.897058, D fake: 0.303599\n",
      "Epoch [41/100], d_loss: 0.452112, g_loss: 2.538254 D real: 0.839237, D fake: 0.123487\n",
      "Epoch [42/100], d_loss: 0.501979, g_loss: 3.133261 D real: 0.852169, D fake: 0.150585\n",
      "Epoch [42/100], d_loss: 0.546696, g_loss: 2.625100 D real: 0.904948, D fake: 0.271031\n",
      "Epoch [42/100], d_loss: 0.510021, g_loss: 2.624668 D real: 0.894768, D fake: 0.239623\n",
      "Epoch [42/100], d_loss: 0.450482, g_loss: 2.746389 D real: 0.866820, D fake: 0.186179\n",
      "Epoch [43/100], d_loss: 0.471771, g_loss: 2.596527 D real: 0.847907, D fake: 0.114044\n",
      "Epoch [43/100], d_loss: 0.407413, g_loss: 2.830528 D real: 0.862962, D fake: 0.120128\n",
      "Epoch [43/100], d_loss: 0.465967, g_loss: 2.849324 D real: 0.894919, D fake: 0.203384\n",
      "Epoch [43/100], d_loss: 0.521326, g_loss: 2.308277 D real: 0.875405, D fake: 0.219308\n",
      "Epoch [44/100], d_loss: 0.569914, g_loss: 2.389763 D real: 0.780710, D fake: 0.108886\n",
      "Epoch [44/100], d_loss: 0.379892, g_loss: 2.366126 D real: 0.860093, D fake: 0.111901\n",
      "Epoch [44/100], d_loss: 0.517600, g_loss: 3.066566 D real: 0.807510, D fake: 0.104335\n",
      "Epoch [44/100], d_loss: 0.407078, g_loss: 2.673508 D real: 0.836320, D fake: 0.108346\n",
      "Epoch [45/100], d_loss: 0.446612, g_loss: 3.528137 D real: 0.855946, D fake: 0.158480\n",
      "Epoch [45/100], d_loss: 0.538905, g_loss: 1.832512 D real: 0.881664, D fake: 0.212072\n",
      "Epoch [45/100], d_loss: 0.462194, g_loss: 2.819175 D real: 0.835225, D fake: 0.137534\n",
      "Epoch [45/100], d_loss: 0.632633, g_loss: 3.354472 D real: 0.775139, D fake: 0.099902\n",
      "Epoch [46/100], d_loss: 0.472280, g_loss: 2.235915 D real: 0.860492, D fake: 0.160663\n",
      "Epoch [46/100], d_loss: 0.453812, g_loss: 3.069668 D real: 0.902131, D fake: 0.182549\n",
      "Epoch [46/100], d_loss: 0.371493, g_loss: 2.882838 D real: 0.863307, D fake: 0.099025\n",
      "Epoch [46/100], d_loss: 0.532033, g_loss: 2.909321 D real: 0.920030, D fake: 0.261657\n",
      "Epoch [47/100], d_loss: 0.488381, g_loss: 3.198915 D real: 0.819422, D fake: 0.112445\n",
      "Epoch [47/100], d_loss: 0.495455, g_loss: 2.180953 D real: 0.862743, D fake: 0.200199\n",
      "Epoch [47/100], d_loss: 0.477063, g_loss: 2.664313 D real: 0.914169, D fake: 0.245260\n",
      "Epoch [47/100], d_loss: 0.461459, g_loss: 3.480652 D real: 0.823324, D fake: 0.081319\n",
      "Epoch [48/100], d_loss: 0.356279, g_loss: 3.213182 D real: 0.874662, D fake: 0.103862\n",
      "Epoch [48/100], d_loss: 0.462456, g_loss: 3.571717 D real: 0.850907, D fake: 0.079546\n",
      "Epoch [48/100], d_loss: 0.438525, g_loss: 3.052740 D real: 0.846885, D fake: 0.144155\n",
      "Epoch [48/100], d_loss: 0.453240, g_loss: 2.443057 D real: 0.835595, D fake: 0.133553\n",
      "Epoch [49/100], d_loss: 0.435780, g_loss: 3.074403 D real: 0.867926, D fake: 0.140742\n",
      "Epoch [49/100], d_loss: 0.420967, g_loss: 3.084408 D real: 0.890766, D fake: 0.167135\n",
      "Epoch [49/100], d_loss: 0.495882, g_loss: 2.573849 D real: 0.826235, D fake: 0.146297\n",
      "Epoch [49/100], d_loss: 0.460768, g_loss: 2.756251 D real: 0.839882, D fake: 0.096031\n",
      "Epoch [50/100], d_loss: 0.493046, g_loss: 3.365831 D real: 0.814273, D fake: 0.082357\n",
      "Epoch [50/100], d_loss: 0.432956, g_loss: 3.104487 D real: 0.886399, D fake: 0.188665\n",
      "Epoch [50/100], d_loss: 0.424147, g_loss: 3.689216 D real: 0.845372, D fake: 0.114225\n",
      "Epoch [50/100], d_loss: 0.437357, g_loss: 2.808270 D real: 0.837870, D fake: 0.105617\n",
      "Epoch [51/100], d_loss: 0.436635, g_loss: 3.651668 D real: 0.865883, D fake: 0.129574\n",
      "Epoch [51/100], d_loss: 0.397376, g_loss: 2.313592 D real: 0.869855, D fake: 0.130486\n",
      "Epoch [51/100], d_loss: 0.417670, g_loss: 3.301390 D real: 0.827303, D fake: 0.069200\n",
      "Epoch [51/100], d_loss: 0.451942, g_loss: 1.984418 D real: 0.850124, D fake: 0.111147\n",
      "Epoch [52/100], d_loss: 0.388548, g_loss: 3.285736 D real: 0.865820, D fake: 0.099175\n",
      "Epoch [52/100], d_loss: 0.399193, g_loss: 3.014504 D real: 0.882781, D fake: 0.146219\n",
      "Epoch [52/100], d_loss: 0.609432, g_loss: 2.320059 D real: 0.790212, D fake: 0.108221\n",
      "Epoch [52/100], d_loss: 0.623948, g_loss: 3.158632 D real: 0.779906, D fake: 0.068369\n",
      "Epoch [53/100], d_loss: 0.610254, g_loss: 3.184006 D real: 0.756762, D fake: 0.073035\n",
      "Epoch [53/100], d_loss: 0.414567, g_loss: 3.014545 D real: 0.855213, D fake: 0.106514\n",
      "Epoch [53/100], d_loss: 0.367569, g_loss: 2.536928 D real: 0.907591, D fake: 0.170133\n",
      "Epoch [53/100], d_loss: 0.585781, g_loss: 3.203052 D real: 0.766634, D fake: 0.059853\n",
      "Epoch [54/100], d_loss: 0.470990, g_loss: 3.390719 D real: 0.822859, D fake: 0.078932\n",
      "Epoch [54/100], d_loss: 0.439094, g_loss: 2.982405 D real: 0.838026, D fake: 0.101314\n",
      "Epoch [54/100], d_loss: 0.391669, g_loss: 2.788538 D real: 0.855359, D fake: 0.099795\n",
      "Epoch [54/100], d_loss: 0.428682, g_loss: 2.492604 D real: 0.876322, D fake: 0.140182\n",
      "Epoch [55/100], d_loss: 0.406541, g_loss: 2.681616 D real: 0.852573, D fake: 0.100384\n",
      "Epoch [55/100], d_loss: 0.418052, g_loss: 2.653108 D real: 0.846435, D fake: 0.088363\n",
      "Epoch [55/100], d_loss: 0.426035, g_loss: 2.740264 D real: 0.898684, D fake: 0.183900\n",
      "Epoch [55/100], d_loss: 0.368398, g_loss: 3.989498 D real: 0.873382, D fake: 0.070808\n",
      "Epoch [56/100], d_loss: 0.338615, g_loss: 2.343866 D real: 0.877360, D fake: 0.107191\n",
      "Epoch [56/100], d_loss: 0.463171, g_loss: 3.377004 D real: 0.831751, D fake: 0.085792\n",
      "Epoch [56/100], d_loss: 0.452674, g_loss: 4.050350 D real: 0.845508, D fake: 0.138736\n",
      "Epoch [56/100], d_loss: 0.440804, g_loss: 2.963718 D real: 0.873500, D fake: 0.149601\n",
      "Epoch [57/100], d_loss: 0.455903, g_loss: 2.369881 D real: 0.858627, D fake: 0.135627\n",
      "Epoch [57/100], d_loss: 0.378858, g_loss: 2.729491 D real: 0.848396, D fake: 0.088791\n",
      "Epoch [57/100], d_loss: 0.539371, g_loss: 3.481474 D real: 0.908562, D fake: 0.219768\n",
      "Epoch [57/100], d_loss: 0.466573, g_loss: 3.195260 D real: 0.844199, D fake: 0.133161\n",
      "Epoch [58/100], d_loss: 0.441895, g_loss: 2.117855 D real: 0.899421, D fake: 0.209639\n",
      "Epoch [58/100], d_loss: 0.411270, g_loss: 3.199414 D real: 0.887549, D fake: 0.148352\n",
      "Epoch [58/100], d_loss: 0.443126, g_loss: 3.495811 D real: 0.821762, D fake: 0.086853\n",
      "Epoch [58/100], d_loss: 0.400305, g_loss: 2.928323 D real: 0.864107, D fake: 0.104875\n",
      "Epoch [59/100], d_loss: 0.388038, g_loss: 2.698039 D real: 0.905535, D fake: 0.134488\n",
      "Epoch [59/100], d_loss: 0.420995, g_loss: 2.590643 D real: 0.838934, D fake: 0.101669\n",
      "Epoch [59/100], d_loss: 0.374280, g_loss: 2.437018 D real: 0.857259, D fake: 0.102318\n",
      "Epoch [59/100], d_loss: 0.360185, g_loss: 2.708186 D real: 0.862686, D fake: 0.078527\n",
      "Epoch [60/100], d_loss: 0.395213, g_loss: 2.072345 D real: 0.853644, D fake: 0.112252\n",
      "Epoch [60/100], d_loss: 0.358198, g_loss: 3.216367 D real: 0.882188, D fake: 0.093679\n",
      "Epoch [60/100], d_loss: 0.447819, g_loss: 2.828257 D real: 0.899741, D fake: 0.208832\n",
      "Epoch [60/100], d_loss: 0.210549, g_loss: 3.631852 D real: 0.924272, D fake: 0.055391\n",
      "Epoch [61/100], d_loss: 0.413816, g_loss: 3.128857 D real: 0.849298, D fake: 0.084561\n",
      "Epoch [61/100], d_loss: 0.349889, g_loss: 2.594808 D real: 0.883787, D fake: 0.119947\n",
      "Epoch [61/100], d_loss: 0.453659, g_loss: 3.018759 D real: 0.825769, D fake: 0.060381\n",
      "Epoch [61/100], d_loss: 0.508016, g_loss: 3.681085 D real: 0.822835, D fake: 0.090292\n",
      "Epoch [62/100], d_loss: 0.308689, g_loss: 3.130468 D real: 0.912747, D fake: 0.131092\n",
      "Epoch [62/100], d_loss: 0.315127, g_loss: 3.231901 D real: 0.899481, D fake: 0.114720\n",
      "Epoch [62/100], d_loss: 0.303618, g_loss: 3.568849 D real: 0.888105, D fake: 0.067295\n",
      "Epoch [62/100], d_loss: 0.378005, g_loss: 3.040994 D real: 0.866146, D fake: 0.097600\n",
      "Epoch [63/100], d_loss: 0.509239, g_loss: 3.312307 D real: 0.802116, D fake: 0.053057\n",
      "Epoch [63/100], d_loss: 0.356118, g_loss: 3.658907 D real: 0.875467, D fake: 0.106092\n",
      "Epoch [63/100], d_loss: 0.457123, g_loss: 2.509578 D real: 0.850378, D fake: 0.126844\n",
      "Epoch [63/100], d_loss: 0.439308, g_loss: 3.045637 D real: 0.853169, D fake: 0.096784\n",
      "Epoch [64/100], d_loss: 0.308333, g_loss: 3.827180 D real: 0.878201, D fake: 0.076337\n",
      "Epoch [64/100], d_loss: 0.403448, g_loss: 3.263901 D real: 0.854823, D fake: 0.111858\n",
      "Epoch [64/100], d_loss: 0.430074, g_loss: 2.697468 D real: 0.899678, D fake: 0.183238\n",
      "Epoch [64/100], d_loss: 0.325594, g_loss: 3.065240 D real: 0.896903, D fake: 0.115246\n",
      "Epoch [65/100], d_loss: 0.341353, g_loss: 3.167591 D real: 0.891895, D fake: 0.125754\n",
      "Epoch [65/100], d_loss: 0.388948, g_loss: 2.764917 D real: 0.921783, D fake: 0.188778\n",
      "Epoch [65/100], d_loss: 0.362466, g_loss: 3.237871 D real: 0.902241, D fake: 0.120001\n",
      "Epoch [65/100], d_loss: 0.358156, g_loss: 3.271741 D real: 0.900723, D fake: 0.154294\n",
      "Epoch [66/100], d_loss: 0.340082, g_loss: 2.842933 D real: 0.923439, D fake: 0.162124\n",
      "Epoch [66/100], d_loss: 0.504439, g_loss: 4.049017 D real: 0.819338, D fake: 0.047531\n",
      "Epoch [66/100], d_loss: 0.288374, g_loss: 3.036790 D real: 0.891248, D fake: 0.097057\n",
      "Epoch [66/100], d_loss: 0.346398, g_loss: 2.229446 D real: 0.904150, D fake: 0.145211\n",
      "Epoch [67/100], d_loss: 0.333283, g_loss: 2.704575 D real: 0.878771, D fake: 0.114318\n",
      "Epoch [67/100], d_loss: 0.304152, g_loss: 3.217154 D real: 0.891152, D fake: 0.087103\n",
      "Epoch [67/100], d_loss: 0.327563, g_loss: 2.580048 D real: 0.907617, D fake: 0.116615\n",
      "Epoch [67/100], d_loss: 0.376837, g_loss: 2.958288 D real: 0.903235, D fake: 0.141424\n",
      "Epoch [68/100], d_loss: 0.303192, g_loss: 3.096857 D real: 0.898617, D fake: 0.097891\n",
      "Epoch [68/100], d_loss: 0.373397, g_loss: 2.236522 D real: 0.921898, D fake: 0.185682\n",
      "Epoch [68/100], d_loss: 0.435502, g_loss: 2.754603 D real: 0.838470, D fake: 0.087962\n",
      "Epoch [68/100], d_loss: 0.364902, g_loss: 3.481915 D real: 0.891804, D fake: 0.108519\n",
      "Epoch [69/100], d_loss: 0.344389, g_loss: 3.497900 D real: 0.871639, D fake: 0.084757\n",
      "Epoch [69/100], d_loss: 0.368817, g_loss: 2.771874 D real: 0.907677, D fake: 0.164034\n",
      "Epoch [69/100], d_loss: 0.382953, g_loss: 3.407177 D real: 0.909401, D fake: 0.121209\n",
      "Epoch [69/100], d_loss: 0.399993, g_loss: 3.385198 D real: 0.881994, D fake: 0.139978\n",
      "Epoch [70/100], d_loss: 0.345688, g_loss: 2.939704 D real: 0.872630, D fake: 0.110060\n",
      "Epoch [70/100], d_loss: 0.394582, g_loss: 3.948417 D real: 0.853168, D fake: 0.098801\n",
      "Epoch [70/100], d_loss: 0.323859, g_loss: 3.408466 D real: 0.901561, D fake: 0.088096\n",
      "Epoch [70/100], d_loss: 0.325526, g_loss: 3.065808 D real: 0.920994, D fake: 0.148569\n",
      "Epoch [71/100], d_loss: 0.340425, g_loss: 3.379567 D real: 0.867880, D fake: 0.068757\n",
      "Epoch [71/100], d_loss: 0.410260, g_loss: 2.830175 D real: 0.875003, D fake: 0.142184\n",
      "Epoch [71/100], d_loss: 0.331694, g_loss: 2.838529 D real: 0.859186, D fake: 0.071298\n",
      "Epoch [71/100], d_loss: 0.401330, g_loss: 2.907112 D real: 0.857119, D fake: 0.096416\n",
      "Epoch [72/100], d_loss: 0.369263, g_loss: 3.363540 D real: 0.895487, D fake: 0.117008\n",
      "Epoch [72/100], d_loss: 0.410432, g_loss: 2.460720 D real: 0.846961, D fake: 0.069629\n",
      "Epoch [72/100], d_loss: 0.338011, g_loss: 3.051948 D real: 0.864678, D fake: 0.058636\n",
      "Epoch [72/100], d_loss: 0.342673, g_loss: 2.844923 D real: 0.912919, D fake: 0.118340\n",
      "Epoch [73/100], d_loss: 0.312689, g_loss: 3.346041 D real: 0.916121, D fake: 0.131858\n",
      "Epoch [73/100], d_loss: 0.277646, g_loss: 3.218314 D real: 0.907186, D fake: 0.102311\n",
      "Epoch [73/100], d_loss: 0.251859, g_loss: 3.821110 D real: 0.894521, D fake: 0.048677\n",
      "Epoch [73/100], d_loss: 0.330706, g_loss: 3.333753 D real: 0.894045, D fake: 0.097025\n",
      "Epoch [74/100], d_loss: 0.313176, g_loss: 2.951689 D real: 0.925144, D fake: 0.133735\n",
      "Epoch [74/100], d_loss: 0.378632, g_loss: 3.250668 D real: 0.888079, D fake: 0.125636\n",
      "Epoch [74/100], d_loss: 0.381628, g_loss: 2.681090 D real: 0.882105, D fake: 0.110201\n",
      "Epoch [74/100], d_loss: 0.377781, g_loss: 3.261451 D real: 0.878269, D fake: 0.091526\n",
      "Epoch [75/100], d_loss: 0.297582, g_loss: 2.830578 D real: 0.916957, D fake: 0.128467\n",
      "Epoch [75/100], d_loss: 0.397118, g_loss: 3.106934 D real: 0.913078, D fake: 0.171816\n",
      "Epoch [75/100], d_loss: 0.252941, g_loss: 3.392542 D real: 0.936624, D fake: 0.106562\n",
      "Epoch [75/100], d_loss: 0.329930, g_loss: 2.898683 D real: 0.892550, D fake: 0.094186\n",
      "Epoch [76/100], d_loss: 0.357739, g_loss: 3.456051 D real: 0.943112, D fake: 0.168384\n",
      "Epoch [76/100], d_loss: 0.321588, g_loss: 2.553248 D real: 0.928964, D fake: 0.129886\n",
      "Epoch [76/100], d_loss: 0.306867, g_loss: 3.513360 D real: 0.931663, D fake: 0.157553\n",
      "Epoch [76/100], d_loss: 0.334988, g_loss: 2.968954 D real: 0.872399, D fake: 0.081425\n",
      "Epoch [77/100], d_loss: 0.293559, g_loss: 3.445335 D real: 0.911494, D fake: 0.102214\n",
      "Epoch [77/100], d_loss: 0.313696, g_loss: 3.737016 D real: 0.931443, D fake: 0.143244\n",
      "Epoch [77/100], d_loss: 0.340486, g_loss: 3.837795 D real: 0.864473, D fake: 0.066727\n",
      "Epoch [77/100], d_loss: 0.378548, g_loss: 2.667950 D real: 0.890909, D fake: 0.121730\n",
      "Epoch [78/100], d_loss: 0.331542, g_loss: 3.069909 D real: 0.883273, D fake: 0.079269\n",
      "Epoch [78/100], d_loss: 0.388330, g_loss: 3.230852 D real: 0.917151, D fake: 0.148062\n",
      "Epoch [78/100], d_loss: 0.434713, g_loss: 3.439574 D real: 0.839878, D fake: 0.072637\n",
      "Epoch [78/100], d_loss: 0.193479, g_loss: 3.657150 D real: 0.948838, D fake: 0.078137\n",
      "Epoch [79/100], d_loss: 0.302492, g_loss: 2.608462 D real: 0.908358, D fake: 0.111966\n",
      "Epoch [79/100], d_loss: 0.305251, g_loss: 3.459300 D real: 0.932388, D fake: 0.112851\n",
      "Epoch [79/100], d_loss: 0.336086, g_loss: 2.991636 D real: 0.906721, D fake: 0.125309\n",
      "Epoch [79/100], d_loss: 0.319933, g_loss: 3.045730 D real: 0.908098, D fake: 0.093441\n",
      "Epoch [80/100], d_loss: 0.341613, g_loss: 2.795382 D real: 0.905281, D fake: 0.137916\n",
      "Epoch [80/100], d_loss: 0.290962, g_loss: 2.900920 D real: 0.908569, D fake: 0.105868\n",
      "Epoch [80/100], d_loss: 0.325498, g_loss: 3.650476 D real: 0.889441, D fake: 0.067932\n",
      "Epoch [80/100], d_loss: 0.365940, g_loss: 2.920571 D real: 0.895593, D fake: 0.111759\n",
      "Epoch [81/100], d_loss: 0.322465, g_loss: 3.311264 D real: 0.923351, D fake: 0.125324\n",
      "Epoch [81/100], d_loss: 0.305331, g_loss: 3.778200 D real: 0.919925, D fake: 0.093732\n",
      "Epoch [81/100], d_loss: 0.256248, g_loss: 3.484890 D real: 0.902326, D fake: 0.060358\n",
      "Epoch [81/100], d_loss: 0.378606, g_loss: 2.327735 D real: 0.907775, D fake: 0.167093\n",
      "Epoch [82/100], d_loss: 0.232851, g_loss: 3.208615 D real: 0.942082, D fake: 0.121151\n",
      "Epoch [82/100], d_loss: 0.368290, g_loss: 3.889655 D real: 0.896925, D fake: 0.116248\n",
      "Epoch [82/100], d_loss: 0.249362, g_loss: 3.739937 D real: 0.923607, D fake: 0.067584\n",
      "Epoch [82/100], d_loss: 0.297742, g_loss: 2.938184 D real: 0.914307, D fake: 0.106346\n",
      "Epoch [83/100], d_loss: 0.316267, g_loss: 3.349068 D real: 0.902720, D fake: 0.095852\n",
      "Epoch [83/100], d_loss: 0.307664, g_loss: 2.603431 D real: 0.947413, D fake: 0.147432\n",
      "Epoch [83/100], d_loss: 0.230873, g_loss: 3.044010 D real: 0.932240, D fake: 0.089736\n",
      "Epoch [83/100], d_loss: 0.351520, g_loss: 2.415660 D real: 0.905148, D fake: 0.150328\n",
      "Epoch [84/100], d_loss: 0.366189, g_loss: 3.375334 D real: 0.964035, D fake: 0.191841\n",
      "Epoch [84/100], d_loss: 0.365517, g_loss: 3.890037 D real: 0.903735, D fake: 0.120315\n",
      "Epoch [84/100], d_loss: 0.254582, g_loss: 3.680930 D real: 0.898789, D fake: 0.049861\n",
      "Epoch [84/100], d_loss: 0.293107, g_loss: 3.465671 D real: 0.887507, D fake: 0.073734\n",
      "Epoch [85/100], d_loss: 0.403931, g_loss: 3.304946 D real: 0.861943, D fake: 0.043922\n",
      "Epoch [85/100], d_loss: 0.373379, g_loss: 4.157855 D real: 0.938835, D fake: 0.165235\n",
      "Epoch [85/100], d_loss: 0.341703, g_loss: 3.347214 D real: 0.883623, D fake: 0.066321\n",
      "Epoch [85/100], d_loss: 0.367580, g_loss: 3.252712 D real: 0.865565, D fake: 0.077198\n",
      "Epoch [86/100], d_loss: 0.408199, g_loss: 3.461830 D real: 0.855923, D fake: 0.056349\n",
      "Epoch [86/100], d_loss: 0.290202, g_loss: 3.817567 D real: 0.901441, D fake: 0.066900\n",
      "Epoch [86/100], d_loss: 0.308388, g_loss: 3.974999 D real: 0.896492, D fake: 0.064459\n",
      "Epoch [86/100], d_loss: 0.319416, g_loss: 3.338582 D real: 0.886687, D fake: 0.085103\n",
      "Epoch [87/100], d_loss: 0.365586, g_loss: 2.761908 D real: 0.869001, D fake: 0.115835\n",
      "Epoch [87/100], d_loss: 0.345250, g_loss: 3.524393 D real: 0.865112, D fake: 0.064342\n",
      "Epoch [87/100], d_loss: 0.297150, g_loss: 3.192005 D real: 0.924297, D fake: 0.114575\n",
      "Epoch [87/100], d_loss: 0.285547, g_loss: 4.470380 D real: 0.898496, D fake: 0.061998\n",
      "Epoch [88/100], d_loss: 0.418842, g_loss: 3.885215 D real: 0.856447, D fake: 0.078178\n",
      "Epoch [88/100], d_loss: 0.282211, g_loss: 3.124354 D real: 0.942982, D fake: 0.119869\n",
      "Epoch [88/100], d_loss: 0.212485, g_loss: 3.295656 D real: 0.927522, D fake: 0.064883\n",
      "Epoch [88/100], d_loss: 0.243212, g_loss: 3.887994 D real: 0.920978, D fake: 0.090010\n",
      "Epoch [89/100], d_loss: 0.241854, g_loss: 3.917837 D real: 0.920295, D fake: 0.087270\n",
      "Epoch [89/100], d_loss: 0.205721, g_loss: 4.532548 D real: 0.940515, D fake: 0.060972\n",
      "Epoch [89/100], d_loss: 0.238784, g_loss: 4.287749 D real: 0.920269, D fake: 0.055284\n",
      "Epoch [89/100], d_loss: 0.335655, g_loss: 3.309927 D real: 0.940554, D fake: 0.160067\n",
      "Epoch [90/100], d_loss: 0.231448, g_loss: 3.385229 D real: 0.924502, D fake: 0.067882\n",
      "Epoch [90/100], d_loss: 0.310352, g_loss: 2.763196 D real: 0.887198, D fake: 0.107842\n",
      "Epoch [90/100], d_loss: 0.369225, g_loss: 3.190340 D real: 0.918774, D fake: 0.150391\n",
      "Epoch [90/100], d_loss: 0.255008, g_loss: 3.281493 D real: 0.887324, D fake: 0.052987\n",
      "Epoch [91/100], d_loss: 0.185662, g_loss: 3.397716 D real: 0.950147, D fake: 0.080471\n",
      "Epoch [91/100], d_loss: 0.297912, g_loss: 4.369614 D real: 0.890004, D fake: 0.034444\n",
      "Epoch [91/100], d_loss: 0.338707, g_loss: 3.383841 D real: 0.890614, D fake: 0.081654\n",
      "Epoch [91/100], d_loss: 0.274433, g_loss: 3.362500 D real: 0.909663, D fake: 0.102080\n",
      "Epoch [92/100], d_loss: 0.165366, g_loss: 3.535721 D real: 0.964087, D fake: 0.067546\n",
      "Epoch [92/100], d_loss: 0.155420, g_loss: 3.793766 D real: 0.944798, D fake: 0.048624\n",
      "Epoch [92/100], d_loss: 0.248609, g_loss: 4.553068 D real: 0.905995, D fake: 0.037301\n",
      "Epoch [92/100], d_loss: 0.388391, g_loss: 2.792447 D real: 0.894860, D fake: 0.130912\n",
      "Epoch [93/100], d_loss: 0.292698, g_loss: 3.934004 D real: 0.879575, D fake: 0.040636\n",
      "Epoch [93/100], d_loss: 0.270678, g_loss: 4.362947 D real: 0.902721, D fake: 0.051236\n",
      "Epoch [93/100], d_loss: 0.271167, g_loss: 4.001272 D real: 0.924571, D fake: 0.090281\n",
      "Epoch [93/100], d_loss: 0.325059, g_loss: 4.162301 D real: 0.896300, D fake: 0.077968\n",
      "Epoch [94/100], d_loss: 0.273889, g_loss: 4.048253 D real: 0.913405, D fake: 0.046601\n",
      "Epoch [94/100], d_loss: 0.380278, g_loss: 2.719907 D real: 0.934684, D fake: 0.181120\n",
      "Epoch [94/100], d_loss: 0.225850, g_loss: 3.545722 D real: 0.966185, D fake: 0.125884\n",
      "Epoch [94/100], d_loss: 0.256376, g_loss: 3.949139 D real: 0.913951, D fake: 0.093252\n",
      "Epoch [95/100], d_loss: 0.201413, g_loss: 2.718653 D real: 0.923888, D fake: 0.047781\n",
      "Epoch [95/100], d_loss: 0.250638, g_loss: 4.622135 D real: 0.909171, D fake: 0.056058\n",
      "Epoch [95/100], d_loss: 0.339476, g_loss: 3.566882 D real: 0.882127, D fake: 0.057333\n",
      "Epoch [95/100], d_loss: 0.260623, g_loss: 3.473399 D real: 0.937266, D fake: 0.124194\n",
      "Epoch [96/100], d_loss: 0.178622, g_loss: 3.909130 D real: 0.933887, D fake: 0.060549\n",
      "Epoch [96/100], d_loss: 0.268258, g_loss: 3.646344 D real: 0.903911, D fake: 0.058047\n",
      "Epoch [96/100], d_loss: 0.382074, g_loss: 3.956010 D real: 0.950442, D fake: 0.187317\n",
      "Epoch [96/100], d_loss: 0.230999, g_loss: 3.991772 D real: 0.916847, D fake: 0.071340\n",
      "Epoch [97/100], d_loss: 0.375284, g_loss: 3.385744 D real: 0.896481, D fake: 0.091115\n",
      "Epoch [97/100], d_loss: 0.259683, g_loss: 3.131967 D real: 0.916065, D fake: 0.060000\n",
      "Epoch [97/100], d_loss: 0.349691, g_loss: 4.379074 D real: 0.888454, D fake: 0.062004\n",
      "Epoch [97/100], d_loss: 0.214275, g_loss: 3.980702 D real: 0.937915, D fake: 0.071810\n",
      "Epoch [98/100], d_loss: 0.151055, g_loss: 3.121060 D real: 0.957058, D fake: 0.076931\n",
      "Epoch [98/100], d_loss: 0.256227, g_loss: 3.824400 D real: 0.934462, D fake: 0.118456\n",
      "Epoch [98/100], d_loss: 0.299627, g_loss: 3.577233 D real: 0.916562, D fake: 0.090153\n",
      "Epoch [98/100], d_loss: 0.194469, g_loss: 3.944954 D real: 0.954891, D fake: 0.091182\n",
      "Epoch [99/100], d_loss: 0.252209, g_loss: 4.394885 D real: 0.914565, D fake: 0.052966\n",
      "Epoch [99/100], d_loss: 0.262799, g_loss: 4.199650 D real: 0.897092, D fake: 0.066922\n",
      "Epoch [99/100], d_loss: 0.256691, g_loss: 3.872373 D real: 0.925898, D fake: 0.076979\n",
      "Epoch [99/100], d_loss: 0.260663, g_loss: 3.162879 D real: 0.920235, D fake: 0.097073\n",
      "Epoch [100/100], d_loss: 0.211714, g_loss: 3.160723 D real: 0.960565, D fake: 0.116924\n",
      "Epoch [100/100], d_loss: 0.270477, g_loss: 3.407452 D real: 0.913434, D fake: 0.075068\n",
      "Epoch [100/100], d_loss: 0.233457, g_loss: 5.246165 D real: 0.919260, D fake: 0.051953\n",
      "Epoch [100/100], d_loss: 0.187755, g_loss: 4.716216 D real: 0.944022, D fake: 0.041021\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(num_epoches):\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # =================train discriminator\n",
    "        real_img = img.to(device)\n",
    "        real_label = torch.ones(num_img).to(device)\n",
    "        fake_label = torch.zeros(num_img).to(device)\n",
    "\n",
    "        # compute loss of real_img\n",
    "        real_out = D(real_img)\n",
    "        d_loss_real = criterion(real_out, real_label)\n",
    "        real_scores = real_out  # closer to 1 means better\n",
    "\n",
    "        # compute loss of fake_img\n",
    "        z = torch.randn(num_img, z_dimension).to(device)\n",
    "        fake_img = G(z)\n",
    "        fake_out = D(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out  # closer to 0 means better\n",
    "\n",
    "        # bp and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # ===============train generator\n",
    "        # compute loss of fake_img\n",
    "        z = torch.randn(num_img, z_dimension).to(device)\n",
    "        fake_img = G(z)\n",
    "        output = D(fake_img)\n",
    "        g_loss = criterion(output, real_label)\n",
    "\n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoches}], d_loss: {d_loss:.6f}, g_loss: {g_loss:.6f} '\n",
    "                  f'D real: {real_scores.mean():.6f}, D fake: {fake_scores.mean():.6f}')\n",
    "\n",
    "    if epoch == 0:\n",
    "        real_images = to_img(real_img)\n",
    "        save_image(real_images, 'save/conv_gan/real_images.png')\n",
    "\n",
    "    fake_images = to_img(fake_img)\n",
    "    save_image(fake_images, f'save/conv_gan/fake_images-{epoch+1:0>3d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), 'save/conv_gan/generator.pytorch')\n",
    "torch.save(D.state_dict(), 'save/conv_gan/discriminator.pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
