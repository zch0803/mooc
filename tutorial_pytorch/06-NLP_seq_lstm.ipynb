{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Process\n",
    "\n",
    "### Seq lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [(\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "                (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])]\n",
    "\n",
    "word_to_idx = {}\n",
    "tag_to_idx = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for context, tag in training_data:\n",
    "    for word in context:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "    for label in tag:\n",
    "        if label not in tag_to_idx:\n",
    "            tag_to_idx[label] = len(tag_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # whether GPU is supportted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_to_idx = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(alphabet)):\n",
    "    character_to_idx[alphabet[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, n_char, char_dim, char_hidden):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.char_embedding = nn.Embedding(n_char, char_dim)\n",
    "        self.char_lstm = nn.LSTM(char_dim, char_hidden, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.char_embedding(x)\n",
    "        _, h = self.char_lstm(x)\n",
    "        return h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self, n_word, n_char, char_dim, n_dim, char_hidden, n_hidden, n_tag):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.word_enbedding = nn.Embedding(n_word, n_dim)\n",
    "        self.char_lstm = CharLSTM(n_char, char_dim, char_hidden)\n",
    "        self.lstm = nn.LSTM(n_dim + char_hidden, n_hidden, batch_first=True)\n",
    "        self.linear1 = nn.Linear(n_hidden, n_tag)\n",
    "        \n",
    "    def forward(self, x, word):\n",
    "        char = torch.FloatTensor()\n",
    "        for each in word:\n",
    "            char_list = []\n",
    "            for letter in each:\n",
    "                char_list.append(character_to_idx[letter.lower()])\n",
    "            char_list = torch.LongTensor(char_list)\n",
    "            char_list = char_list.unsqueeze(0)\n",
    "            tempchar = char_list #.to(device)\n",
    "#             tempchar = tempchar.squeeze(0)\n",
    "            char = torch.cat((char, tempchar.cpu()), 0)\n",
    "#         char = char.to(device)\n",
    "        x = self.word_enbedding(x)\n",
    "        x = torch.cat((x, char), 1)\n",
    "        x = x.unsqueeze(0)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.squeeze(0)\n",
    "        x = self.linear1(x)\n",
    "        y = F.log_softmax(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(len(word_to_idx), len(character_to_idx), 10, 100, 50, 128, len(tag_to_idx)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequence(x, dic):\n",
    "    idx = [dic[i] for i in x]\n",
    "    idx = torch.LongTensor(idx)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(300):\n",
    "    print('*' * 10)\n",
    "    print(f'epoch {epoch+1}')\n",
    "    running_loss = 0\n",
    "    for data in training_data:\n",
    "        word, tag = data\n",
    "        word_list = make_sequence(word, word_to_idx)\n",
    "        tag = make_sequence(tag, tag_to_idx)\n",
    "        word_list, tag = word_list.to(device), tag.to(device)\n",
    "        # forward\n",
    "        out = model(word_list, word)\n",
    "        loss = criterion(out, tag)\n",
    "        running_loss += loss.data\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Loss: {running_loss/len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = make_sequence(\"Everybody ate the apple\".split(), word_to_idx)\n",
    "input = input.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input, \"Everybody ate the apple\".split())\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
