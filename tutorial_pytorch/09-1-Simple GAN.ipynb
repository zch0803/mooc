{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('save/sim_gan'):\n",
    "    os.mkdir('save/sim_gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    out = 0.5 * (x + 1)\n",
    "    out = out.clamp(0, 1)\n",
    "    out = out.reshape(-1, 1, 28, 28)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoches = 100\n",
    "batch_size = 128\n",
    "z_dimension = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # whether GPU is supportted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist = datasets.MNIST('../_data/mnist', train=True, transform=img_transform, download=True)\n",
    "# Data loader\n",
    "dataloader = DataLoader(dataset=mnist, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2), nn.Linear(256, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 256), nn.ReLU(True), nn.Linear(256, 784), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator().to(device)\n",
    "G = generator().to(device)\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], d_loss: 0.135319, g_loss: 3.752518 D real: 0.963787, D fake: 0.091794\n",
      "Epoch [0/100], d_loss: 0.031493, g_loss: 5.028942 D real: 0.987179, D fake: 0.018191\n",
      "Epoch [0/100], d_loss: 0.237485, g_loss: 5.412944 D real: 0.966075, D fake: 0.164920\n",
      "Epoch [0/100], d_loss: 0.034377, g_loss: 6.113669 D real: 0.996366, D fake: 0.029698\n",
      "Epoch [1/100], d_loss: 0.085341, g_loss: 4.118917 D real: 0.982024, D fake: 0.046382\n",
      "Epoch [1/100], d_loss: 0.200163, g_loss: 4.582250 D real: 0.965505, D fake: 0.119338\n",
      "Epoch [1/100], d_loss: 0.140504, g_loss: 5.526665 D real: 0.950282, D fake: 0.050234\n",
      "Epoch [1/100], d_loss: 0.547503, g_loss: 5.642103 D real: 0.927914, D fake: 0.292087\n",
      "Epoch [2/100], d_loss: 0.420671, g_loss: 6.848865 D real: 0.935520, D fake: 0.193164\n",
      "Epoch [2/100], d_loss: 0.818404, g_loss: 6.327253 D real: 0.859086, D fake: 0.304561\n",
      "Epoch [2/100], d_loss: 0.219319, g_loss: 3.305739 D real: 0.948900, D fake: 0.132807\n",
      "Epoch [2/100], d_loss: 0.440326, g_loss: 3.102167 D real: 0.866642, D fake: 0.127957\n",
      "Epoch [3/100], d_loss: 0.328202, g_loss: 4.791496 D real: 0.894474, D fake: 0.124044\n",
      "Epoch [3/100], d_loss: 0.347984, g_loss: 5.911924 D real: 0.899298, D fake: 0.083028\n",
      "Epoch [3/100], d_loss: 0.433645, g_loss: 2.799721 D real: 0.909660, D fake: 0.227241\n",
      "Epoch [3/100], d_loss: 0.785143, g_loss: 4.396314 D real: 0.836138, D fake: 0.258820\n",
      "Epoch [4/100], d_loss: 1.977719, g_loss: 1.555606 D real: 0.485544, D fake: 0.291879\n",
      "Epoch [4/100], d_loss: 0.376991, g_loss: 3.834438 D real: 0.899913, D fake: 0.188758\n",
      "Epoch [4/100], d_loss: 0.114032, g_loss: 4.183141 D real: 0.945504, D fake: 0.044215\n",
      "Epoch [4/100], d_loss: 0.876804, g_loss: 2.131371 D real: 0.766044, D fake: 0.336799\n",
      "Epoch [5/100], d_loss: 0.608175, g_loss: 3.342622 D real: 0.829960, D fake: 0.217907\n",
      "Epoch [5/100], d_loss: 2.025953, g_loss: 3.265183 D real: 0.583237, D fake: 0.309648\n",
      "Epoch [5/100], d_loss: 0.678039, g_loss: 4.467609 D real: 0.844962, D fake: 0.219764\n",
      "Epoch [5/100], d_loss: 0.408233, g_loss: 4.465511 D real: 0.834536, D fake: 0.074532\n",
      "Epoch [6/100], d_loss: 0.415767, g_loss: 2.544548 D real: 0.865973, D fake: 0.185826\n",
      "Epoch [6/100], d_loss: 0.622831, g_loss: 2.348195 D real: 0.836515, D fake: 0.236614\n",
      "Epoch [6/100], d_loss: 0.287838, g_loss: 3.235757 D real: 0.944349, D fake: 0.155004\n",
      "Epoch [6/100], d_loss: 1.205794, g_loss: 2.350551 D real: 0.749749, D fake: 0.457721\n",
      "Epoch [7/100], d_loss: 0.117474, g_loss: 3.177228 D real: 0.985312, D fake: 0.093228\n",
      "Epoch [7/100], d_loss: 0.373127, g_loss: 2.786923 D real: 0.856617, D fake: 0.093962\n",
      "Epoch [7/100], d_loss: 0.217897, g_loss: 3.905855 D real: 0.925264, D fake: 0.063667\n",
      "Epoch [7/100], d_loss: 0.462308, g_loss: 2.371324 D real: 0.884462, D fake: 0.140750\n",
      "Epoch [8/100], d_loss: 0.226730, g_loss: 4.120714 D real: 0.931053, D fake: 0.067749\n",
      "Epoch [8/100], d_loss: 0.619516, g_loss: 1.956278 D real: 0.820789, D fake: 0.165890\n",
      "Epoch [8/100], d_loss: 0.431415, g_loss: 3.654687 D real: 0.852647, D fake: 0.061348\n",
      "Epoch [8/100], d_loss: 0.199361, g_loss: 2.840695 D real: 0.975345, D fake: 0.143057\n",
      "Epoch [9/100], d_loss: 0.626518, g_loss: 2.944786 D real: 0.828193, D fake: 0.159129\n",
      "Epoch [9/100], d_loss: 0.390102, g_loss: 3.521914 D real: 0.874464, D fake: 0.138701\n",
      "Epoch [9/100], d_loss: 0.413725, g_loss: 3.283393 D real: 0.857023, D fake: 0.084484\n",
      "Epoch [9/100], d_loss: 0.581002, g_loss: 2.668162 D real: 0.889087, D fake: 0.225280\n",
      "Epoch [10/100], d_loss: 0.829234, g_loss: 2.567140 D real: 0.698455, D fake: 0.149461\n",
      "Epoch [10/100], d_loss: 0.510064, g_loss: 3.053922 D real: 0.869270, D fake: 0.205450\n",
      "Epoch [10/100], d_loss: 0.500926, g_loss: 3.336131 D real: 0.834804, D fake: 0.127413\n",
      "Epoch [10/100], d_loss: 0.368392, g_loss: 2.947032 D real: 0.866245, D fake: 0.132626\n",
      "Epoch [11/100], d_loss: 0.366037, g_loss: 4.573988 D real: 0.841148, D fake: 0.044245\n",
      "Epoch [11/100], d_loss: 0.480931, g_loss: 3.784292 D real: 0.878293, D fake: 0.186724\n",
      "Epoch [11/100], d_loss: 0.280893, g_loss: 3.420514 D real: 0.920403, D fake: 0.110386\n",
      "Epoch [11/100], d_loss: 0.247751, g_loss: 3.337669 D real: 0.917097, D fake: 0.098089\n",
      "Epoch [12/100], d_loss: 0.481858, g_loss: 3.207515 D real: 0.883175, D fake: 0.183334\n",
      "Epoch [12/100], d_loss: 0.157649, g_loss: 3.588623 D real: 0.946520, D fake: 0.041817\n",
      "Epoch [12/100], d_loss: 0.353870, g_loss: 3.613913 D real: 0.895693, D fake: 0.123115\n",
      "Epoch [12/100], d_loss: 0.553443, g_loss: 2.225167 D real: 0.849671, D fake: 0.127368\n",
      "Epoch [13/100], d_loss: 0.314214, g_loss: 5.162555 D real: 0.905095, D fake: 0.049475\n",
      "Epoch [13/100], d_loss: 1.137567, g_loss: 3.052334 D real: 0.830168, D fake: 0.322352\n",
      "Epoch [13/100], d_loss: 0.355083, g_loss: 4.324669 D real: 0.924901, D fake: 0.159101\n",
      "Epoch [13/100], d_loss: 0.186447, g_loss: 5.493178 D real: 0.925641, D fake: 0.057153\n",
      "Epoch [14/100], d_loss: 0.291877, g_loss: 3.722708 D real: 0.882751, D fake: 0.061281\n",
      "Epoch [14/100], d_loss: 0.196834, g_loss: 3.383520 D real: 0.926752, D fake: 0.048228\n",
      "Epoch [14/100], d_loss: 0.163537, g_loss: 3.668111 D real: 0.940444, D fake: 0.056066\n",
      "Epoch [14/100], d_loss: 0.286647, g_loss: 4.194643 D real: 0.893834, D fake: 0.029187\n",
      "Epoch [15/100], d_loss: 0.185157, g_loss: 4.874808 D real: 0.945338, D fake: 0.063311\n",
      "Epoch [15/100], d_loss: 0.260733, g_loss: 3.632031 D real: 0.946935, D fake: 0.129315\n",
      "Epoch [15/100], d_loss: 0.310473, g_loss: 3.987071 D real: 0.938588, D fake: 0.137746\n",
      "Epoch [15/100], d_loss: 0.244133, g_loss: 5.992276 D real: 0.916726, D fake: 0.032922\n",
      "Epoch [16/100], d_loss: 0.308703, g_loss: 4.846384 D real: 0.895240, D fake: 0.064761\n",
      "Epoch [16/100], d_loss: 0.502683, g_loss: 3.740484 D real: 0.834624, D fake: 0.111227\n",
      "Epoch [16/100], d_loss: 0.573473, g_loss: 4.728504 D real: 0.934732, D fake: 0.249862\n",
      "Epoch [16/100], d_loss: 0.251675, g_loss: 4.216563 D real: 0.930278, D fake: 0.115777\n",
      "Epoch [17/100], d_loss: 0.433064, g_loss: 4.135287 D real: 0.895190, D fake: 0.143687\n",
      "Epoch [17/100], d_loss: 0.281125, g_loss: 5.206500 D real: 0.907041, D fake: 0.029053\n",
      "Epoch [17/100], d_loss: 0.395827, g_loss: 3.879028 D real: 0.864540, D fake: 0.084844\n",
      "Epoch [17/100], d_loss: 0.432195, g_loss: 3.979006 D real: 0.848658, D fake: 0.077290\n",
      "Epoch [18/100], d_loss: 0.415073, g_loss: 3.266095 D real: 0.904241, D fake: 0.135463\n",
      "Epoch [18/100], d_loss: 0.342437, g_loss: 3.665721 D real: 0.896096, D fake: 0.122673\n",
      "Epoch [18/100], d_loss: 0.337413, g_loss: 4.655554 D real: 0.908401, D fake: 0.030212\n",
      "Epoch [18/100], d_loss: 0.313970, g_loss: 4.416286 D real: 0.880477, D fake: 0.049450\n",
      "Epoch [19/100], d_loss: 0.562433, g_loss: 4.371310 D real: 0.910250, D fake: 0.234206\n",
      "Epoch [19/100], d_loss: 0.327469, g_loss: 3.565388 D real: 0.914058, D fake: 0.137197\n",
      "Epoch [19/100], d_loss: 0.466552, g_loss: 5.640919 D real: 0.852305, D fake: 0.016605\n",
      "Epoch [19/100], d_loss: 0.189759, g_loss: 4.564258 D real: 0.948837, D fake: 0.082869\n",
      "Epoch [20/100], d_loss: 0.225759, g_loss: 4.229395 D real: 0.916205, D fake: 0.058194\n",
      "Epoch [20/100], d_loss: 0.186759, g_loss: 4.041779 D real: 0.926483, D fake: 0.065367\n",
      "Epoch [20/100], d_loss: 0.283628, g_loss: 4.080162 D real: 0.915998, D fake: 0.094178\n",
      "Epoch [20/100], d_loss: 0.388245, g_loss: 4.769054 D real: 0.886798, D fake: 0.074966\n",
      "Epoch [21/100], d_loss: 0.517721, g_loss: 3.487725 D real: 0.843021, D fake: 0.086648\n",
      "Epoch [21/100], d_loss: 0.389915, g_loss: 3.774762 D real: 0.891667, D fake: 0.111493\n",
      "Epoch [21/100], d_loss: 0.484992, g_loss: 3.852957 D real: 0.859190, D fake: 0.121019\n",
      "Epoch [21/100], d_loss: 0.670408, g_loss: 5.001585 D real: 0.831298, D fake: 0.123344\n",
      "Epoch [22/100], d_loss: 0.176339, g_loss: 5.196103 D real: 0.949725, D fake: 0.085929\n",
      "Epoch [22/100], d_loss: 0.222741, g_loss: 5.125340 D real: 0.926157, D fake: 0.083764\n",
      "Epoch [22/100], d_loss: 0.331216, g_loss: 4.923429 D real: 0.899514, D fake: 0.089512\n",
      "Epoch [22/100], d_loss: 0.469769, g_loss: 3.875831 D real: 0.844603, D fake: 0.061990\n",
      "Epoch [23/100], d_loss: 0.762636, g_loss: 3.132243 D real: 0.789195, D fake: 0.091348\n",
      "Epoch [23/100], d_loss: 0.784367, g_loss: 3.052477 D real: 0.865379, D fake: 0.300699\n",
      "Epoch [23/100], d_loss: 0.682348, g_loss: 2.613236 D real: 0.820969, D fake: 0.201056\n",
      "Epoch [23/100], d_loss: 0.798465, g_loss: 3.260856 D real: 0.796187, D fake: 0.222133\n",
      "Epoch [24/100], d_loss: 0.867459, g_loss: 3.291893 D real: 0.816339, D fake: 0.243003\n",
      "Epoch [24/100], d_loss: 0.326912, g_loss: 3.472869 D real: 0.853348, D fake: 0.056352\n",
      "Epoch [24/100], d_loss: 0.573783, g_loss: 2.929419 D real: 0.860753, D fake: 0.197946\n",
      "Epoch [24/100], d_loss: 0.587731, g_loss: 1.912855 D real: 0.843701, D fake: 0.220552\n",
      "Epoch [25/100], d_loss: 0.331361, g_loss: 2.968867 D real: 0.885877, D fake: 0.105616\n",
      "Epoch [25/100], d_loss: 0.229254, g_loss: 3.333608 D real: 0.953987, D fake: 0.117697\n",
      "Epoch [25/100], d_loss: 0.401827, g_loss: 2.446764 D real: 0.909880, D fake: 0.195315\n",
      "Epoch [25/100], d_loss: 0.645782, g_loss: 2.559640 D real: 0.821471, D fake: 0.123501\n",
      "Epoch [26/100], d_loss: 0.360116, g_loss: 3.883364 D real: 0.862381, D fake: 0.044827\n",
      "Epoch [26/100], d_loss: 0.347665, g_loss: 3.881556 D real: 0.865638, D fake: 0.076627\n",
      "Epoch [26/100], d_loss: 0.281094, g_loss: 3.732048 D real: 0.888201, D fake: 0.091280\n",
      "Epoch [26/100], d_loss: 0.322742, g_loss: 2.940971 D real: 0.914762, D fake: 0.144728\n",
      "Epoch [27/100], d_loss: 0.366590, g_loss: 4.264009 D real: 0.883115, D fake: 0.092036\n",
      "Epoch [27/100], d_loss: 0.229480, g_loss: 4.455960 D real: 0.945269, D fake: 0.086467\n",
      "Epoch [27/100], d_loss: 0.536707, g_loss: 2.974533 D real: 0.852176, D fake: 0.155414\n",
      "Epoch [27/100], d_loss: 0.333774, g_loss: 3.801531 D real: 0.883057, D fake: 0.075175\n",
      "Epoch [28/100], d_loss: 0.287898, g_loss: 3.767646 D real: 0.920303, D fake: 0.108481\n",
      "Epoch [28/100], d_loss: 0.322309, g_loss: 3.600951 D real: 0.918095, D fake: 0.133908\n",
      "Epoch [28/100], d_loss: 0.453165, g_loss: 2.414798 D real: 0.885396, D fake: 0.158678\n",
      "Epoch [28/100], d_loss: 0.620226, g_loss: 2.943063 D real: 0.904545, D fake: 0.253211\n",
      "Epoch [29/100], d_loss: 0.328883, g_loss: 3.460562 D real: 0.900625, D fake: 0.116668\n",
      "Epoch [29/100], d_loss: 0.517161, g_loss: 3.737881 D real: 0.805536, D fake: 0.075382\n",
      "Epoch [29/100], d_loss: 0.399786, g_loss: 2.999982 D real: 0.863314, D fake: 0.144615\n",
      "Epoch [29/100], d_loss: 0.634855, g_loss: 2.497146 D real: 0.817036, D fake: 0.164649\n",
      "Epoch [30/100], d_loss: 0.453642, g_loss: 3.078118 D real: 0.913127, D fake: 0.212949\n",
      "Epoch [30/100], d_loss: 0.757438, g_loss: 2.827256 D real: 0.766200, D fake: 0.185330\n",
      "Epoch [30/100], d_loss: 0.326230, g_loss: 2.960770 D real: 0.905150, D fake: 0.155885\n",
      "Epoch [30/100], d_loss: 0.653925, g_loss: 2.363142 D real: 0.785191, D fake: 0.165065\n",
      "Epoch [31/100], d_loss: 0.559350, g_loss: 3.293951 D real: 0.789778, D fake: 0.111136\n",
      "Epoch [31/100], d_loss: 0.348789, g_loss: 3.273699 D real: 0.872455, D fake: 0.130958\n",
      "Epoch [31/100], d_loss: 0.424254, g_loss: 3.315771 D real: 0.894267, D fake: 0.164348\n",
      "Epoch [31/100], d_loss: 0.442589, g_loss: 2.956115 D real: 0.898555, D fake: 0.173650\n",
      "Epoch [32/100], d_loss: 0.458932, g_loss: 2.883163 D real: 0.872086, D fake: 0.145767\n",
      "Epoch [32/100], d_loss: 0.524236, g_loss: 3.506377 D real: 0.828514, D fake: 0.119804\n",
      "Epoch [32/100], d_loss: 0.539952, g_loss: 3.259991 D real: 0.852350, D fake: 0.188384\n",
      "Epoch [32/100], d_loss: 0.491810, g_loss: 2.356045 D real: 0.885891, D fake: 0.179718\n",
      "Epoch [33/100], d_loss: 0.416581, g_loss: 3.618837 D real: 0.865466, D fake: 0.123283\n",
      "Epoch [33/100], d_loss: 0.628567, g_loss: 3.570012 D real: 0.790859, D fake: 0.147145\n",
      "Epoch [33/100], d_loss: 0.485667, g_loss: 3.991562 D real: 0.843562, D fake: 0.111852\n",
      "Epoch [33/100], d_loss: 0.219968, g_loss: 3.460794 D real: 0.921093, D fake: 0.094775\n",
      "Epoch [34/100], d_loss: 0.458279, g_loss: 2.401423 D real: 0.894906, D fake: 0.183004\n",
      "Epoch [34/100], d_loss: 0.555628, g_loss: 3.035407 D real: 0.912343, D fake: 0.238175\n",
      "Epoch [34/100], d_loss: 0.498419, g_loss: 3.230615 D real: 0.838933, D fake: 0.141747\n",
      "Epoch [34/100], d_loss: 0.513685, g_loss: 3.379155 D real: 0.841985, D fake: 0.125936\n",
      "Epoch [35/100], d_loss: 0.490170, g_loss: 3.732062 D real: 0.859523, D fake: 0.160852\n",
      "Epoch [35/100], d_loss: 0.332270, g_loss: 4.065773 D real: 0.895249, D fake: 0.126898\n",
      "Epoch [35/100], d_loss: 0.481826, g_loss: 2.378688 D real: 0.860414, D fake: 0.166502\n",
      "Epoch [35/100], d_loss: 0.598668, g_loss: 2.527089 D real: 0.804527, D fake: 0.171206\n",
      "Epoch [36/100], d_loss: 0.519457, g_loss: 3.043790 D real: 0.903552, D fake: 0.235028\n",
      "Epoch [36/100], d_loss: 0.563730, g_loss: 3.133562 D real: 0.888146, D fake: 0.260155\n",
      "Epoch [36/100], d_loss: 0.390531, g_loss: 2.985232 D real: 0.885609, D fake: 0.124909\n",
      "Epoch [36/100], d_loss: 0.419669, g_loss: 2.063952 D real: 0.850607, D fake: 0.137127\n",
      "Epoch [37/100], d_loss: 0.585387, g_loss: 3.337409 D real: 0.830763, D fake: 0.186458\n",
      "Epoch [37/100], d_loss: 0.480908, g_loss: 3.569679 D real: 0.919008, D fake: 0.223002\n",
      "Epoch [37/100], d_loss: 0.462948, g_loss: 3.230820 D real: 0.861886, D fake: 0.149281\n",
      "Epoch [37/100], d_loss: 0.348969, g_loss: 2.814679 D real: 0.908064, D fake: 0.137804\n",
      "Epoch [38/100], d_loss: 0.683076, g_loss: 2.670099 D real: 0.755705, D fake: 0.108201\n",
      "Epoch [38/100], d_loss: 0.438798, g_loss: 2.462055 D real: 0.868331, D fake: 0.170101\n",
      "Epoch [38/100], d_loss: 0.559637, g_loss: 2.482665 D real: 0.803718, D fake: 0.162070\n",
      "Epoch [38/100], d_loss: 0.630259, g_loss: 2.818833 D real: 0.796126, D fake: 0.155333\n",
      "Epoch [39/100], d_loss: 0.560547, g_loss: 3.367740 D real: 0.817593, D fake: 0.153946\n",
      "Epoch [39/100], d_loss: 0.497069, g_loss: 3.018607 D real: 0.815728, D fake: 0.120139\n",
      "Epoch [39/100], d_loss: 0.559639, g_loss: 3.014796 D real: 0.818542, D fake: 0.127020\n",
      "Epoch [39/100], d_loss: 0.556459, g_loss: 2.544746 D real: 0.768947, D fake: 0.095696\n",
      "Epoch [40/100], d_loss: 0.760594, g_loss: 2.173827 D real: 0.797282, D fake: 0.219839\n",
      "Epoch [40/100], d_loss: 0.421636, g_loss: 3.102743 D real: 0.885765, D fake: 0.175983\n",
      "Epoch [40/100], d_loss: 0.412147, g_loss: 2.675806 D real: 0.861683, D fake: 0.158239\n",
      "Epoch [40/100], d_loss: 0.542056, g_loss: 2.726959 D real: 0.883829, D fake: 0.237275\n",
      "Epoch [41/100], d_loss: 0.416919, g_loss: 2.635454 D real: 0.890203, D fake: 0.160618\n",
      "Epoch [41/100], d_loss: 0.568754, g_loss: 2.332119 D real: 0.853476, D fake: 0.219966\n",
      "Epoch [41/100], d_loss: 0.541361, g_loss: 2.575817 D real: 0.806256, D fake: 0.115897\n",
      "Epoch [41/100], d_loss: 0.583120, g_loss: 2.994206 D real: 0.820687, D fake: 0.176026\n",
      "Epoch [42/100], d_loss: 0.388967, g_loss: 3.613402 D real: 0.897975, D fake: 0.167103\n",
      "Epoch [42/100], d_loss: 0.424099, g_loss: 3.410379 D real: 0.839560, D fake: 0.093019\n",
      "Epoch [42/100], d_loss: 0.442954, g_loss: 3.333798 D real: 0.867238, D fake: 0.162365\n",
      "Epoch [42/100], d_loss: 0.887621, g_loss: 2.348453 D real: 0.826322, D fake: 0.294166\n",
      "Epoch [43/100], d_loss: 0.613420, g_loss: 2.551896 D real: 0.900285, D fake: 0.252210\n",
      "Epoch [43/100], d_loss: 0.608933, g_loss: 2.058808 D real: 0.804621, D fake: 0.150960\n",
      "Epoch [43/100], d_loss: 0.551005, g_loss: 2.978104 D real: 0.848418, D fake: 0.178449\n",
      "Epoch [43/100], d_loss: 0.582557, g_loss: 2.142571 D real: 0.868130, D fake: 0.249800\n",
      "Epoch [44/100], d_loss: 0.474814, g_loss: 2.871090 D real: 0.856819, D fake: 0.155391\n",
      "Epoch [44/100], d_loss: 0.585022, g_loss: 3.325540 D real: 0.853626, D fake: 0.219778\n",
      "Epoch [44/100], d_loss: 0.672699, g_loss: 2.885320 D real: 0.844456, D fake: 0.232857\n",
      "Epoch [44/100], d_loss: 0.667692, g_loss: 2.420011 D real: 0.795062, D fake: 0.191646\n",
      "Epoch [45/100], d_loss: 0.588814, g_loss: 3.240149 D real: 0.822495, D fake: 0.147901\n",
      "Epoch [45/100], d_loss: 0.518860, g_loss: 2.193007 D real: 0.803348, D fake: 0.129098\n",
      "Epoch [45/100], d_loss: 0.361857, g_loss: 3.434869 D real: 0.924592, D fake: 0.183257\n",
      "Epoch [45/100], d_loss: 0.476020, g_loss: 2.612416 D real: 0.894221, D fake: 0.216589\n",
      "Epoch [46/100], d_loss: 0.928632, g_loss: 2.044060 D real: 0.786253, D fake: 0.280948\n",
      "Epoch [46/100], d_loss: 0.483297, g_loss: 2.560444 D real: 0.821276, D fake: 0.114283\n",
      "Epoch [46/100], d_loss: 0.511691, g_loss: 2.780278 D real: 0.845220, D fake: 0.174764\n",
      "Epoch [46/100], d_loss: 0.603876, g_loss: 2.801206 D real: 0.839223, D fake: 0.235023\n",
      "Epoch [47/100], d_loss: 0.497067, g_loss: 2.289674 D real: 0.848924, D fake: 0.165462\n",
      "Epoch [47/100], d_loss: 0.455974, g_loss: 2.932919 D real: 0.850798, D fake: 0.164956\n",
      "Epoch [47/100], d_loss: 0.729186, g_loss: 2.442344 D real: 0.737513, D fake: 0.140086\n",
      "Epoch [47/100], d_loss: 0.683974, g_loss: 2.691861 D real: 0.758806, D fake: 0.150124\n",
      "Epoch [48/100], d_loss: 0.818120, g_loss: 2.671006 D real: 0.822608, D fake: 0.285586\n",
      "Epoch [48/100], d_loss: 0.539966, g_loss: 2.181109 D real: 0.874548, D fake: 0.236572\n",
      "Epoch [48/100], d_loss: 0.605104, g_loss: 2.775809 D real: 0.841446, D fake: 0.204425\n",
      "Epoch [48/100], d_loss: 0.643102, g_loss: 2.761861 D real: 0.748423, D fake: 0.128290\n",
      "Epoch [49/100], d_loss: 0.691363, g_loss: 1.698247 D real: 0.830672, D fake: 0.244711\n",
      "Epoch [49/100], d_loss: 0.659093, g_loss: 2.019825 D real: 0.870335, D fake: 0.281381\n",
      "Epoch [49/100], d_loss: 0.495648, g_loss: 2.379055 D real: 0.882278, D fake: 0.226253\n",
      "Epoch [49/100], d_loss: 0.884302, g_loss: 2.043958 D real: 0.734528, D fake: 0.206797\n",
      "Epoch [50/100], d_loss: 0.714964, g_loss: 2.490353 D real: 0.796009, D fake: 0.195637\n",
      "Epoch [50/100], d_loss: 0.601901, g_loss: 2.243404 D real: 0.813752, D fake: 0.184273\n",
      "Epoch [50/100], d_loss: 0.455726, g_loss: 2.601261 D real: 0.831166, D fake: 0.136161\n",
      "Epoch [50/100], d_loss: 0.637317, g_loss: 2.560037 D real: 0.777886, D fake: 0.134070\n",
      "Epoch [51/100], d_loss: 0.638356, g_loss: 1.965605 D real: 0.782400, D fake: 0.195796\n",
      "Epoch [51/100], d_loss: 0.563325, g_loss: 2.942036 D real: 0.858972, D fake: 0.197659\n",
      "Epoch [51/100], d_loss: 0.493448, g_loss: 3.448148 D real: 0.853636, D fake: 0.127592\n",
      "Epoch [51/100], d_loss: 0.380158, g_loss: 2.574378 D real: 0.901900, D fake: 0.195520\n",
      "Epoch [52/100], d_loss: 0.625132, g_loss: 2.535397 D real: 0.727919, D fake: 0.125234\n",
      "Epoch [52/100], d_loss: 0.688240, g_loss: 2.502676 D real: 0.739151, D fake: 0.129212\n",
      "Epoch [52/100], d_loss: 0.556728, g_loss: 3.691636 D real: 0.771829, D fake: 0.083672\n",
      "Epoch [52/100], d_loss: 0.493659, g_loss: 3.136207 D real: 0.854372, D fake: 0.154716\n",
      "Epoch [53/100], d_loss: 0.453572, g_loss: 3.546599 D real: 0.858483, D fake: 0.147908\n",
      "Epoch [53/100], d_loss: 0.484725, g_loss: 2.767375 D real: 0.874787, D fake: 0.173040\n",
      "Epoch [53/100], d_loss: 0.452698, g_loss: 2.300981 D real: 0.813191, D fake: 0.091778\n",
      "Epoch [53/100], d_loss: 0.402648, g_loss: 3.254551 D real: 0.882224, D fake: 0.141405\n",
      "Epoch [54/100], d_loss: 0.564639, g_loss: 2.852556 D real: 0.884102, D fake: 0.240439\n",
      "Epoch [54/100], d_loss: 0.370362, g_loss: 2.799943 D real: 0.880853, D fake: 0.138026\n",
      "Epoch [54/100], d_loss: 0.667252, g_loss: 3.233670 D real: 0.823245, D fake: 0.215213\n",
      "Epoch [54/100], d_loss: 0.356657, g_loss: 2.437723 D real: 0.881446, D fake: 0.130506\n",
      "Epoch [55/100], d_loss: 0.714837, g_loss: 3.062238 D real: 0.757477, D fake: 0.131552\n",
      "Epoch [55/100], d_loss: 0.651051, g_loss: 1.852655 D real: 0.803546, D fake: 0.191418\n",
      "Epoch [55/100], d_loss: 0.608069, g_loss: 2.804626 D real: 0.916568, D fake: 0.293106\n",
      "Epoch [55/100], d_loss: 0.582118, g_loss: 2.632653 D real: 0.821703, D fake: 0.190724\n",
      "Epoch [56/100], d_loss: 0.496061, g_loss: 3.074556 D real: 0.830904, D fake: 0.155938\n",
      "Epoch [56/100], d_loss: 0.531079, g_loss: 2.447660 D real: 0.880812, D fake: 0.230988\n",
      "Epoch [56/100], d_loss: 0.507078, g_loss: 2.426060 D real: 0.815769, D fake: 0.144544\n",
      "Epoch [56/100], d_loss: 0.669070, g_loss: 2.042100 D real: 0.792532, D fake: 0.209991\n",
      "Epoch [57/100], d_loss: 0.409962, g_loss: 3.027907 D real: 0.862563, D fake: 0.142803\n",
      "Epoch [57/100], d_loss: 0.438631, g_loss: 3.477701 D real: 0.847793, D fake: 0.136540\n",
      "Epoch [57/100], d_loss: 0.418575, g_loss: 3.232974 D real: 0.836593, D fake: 0.111469\n",
      "Epoch [57/100], d_loss: 0.717535, g_loss: 2.032479 D real: 0.760789, D fake: 0.139719\n",
      "Epoch [58/100], d_loss: 0.621580, g_loss: 2.384924 D real: 0.823151, D fake: 0.203451\n",
      "Epoch [58/100], d_loss: 0.614009, g_loss: 1.979734 D real: 0.838043, D fake: 0.252449\n",
      "Epoch [58/100], d_loss: 0.718438, g_loss: 3.074488 D real: 0.809509, D fake: 0.271050\n",
      "Epoch [58/100], d_loss: 0.612119, g_loss: 2.906093 D real: 0.784603, D fake: 0.144849\n",
      "Epoch [59/100], d_loss: 0.528025, g_loss: 2.672750 D real: 0.835513, D fake: 0.164869\n",
      "Epoch [59/100], d_loss: 0.648952, g_loss: 2.422346 D real: 0.800003, D fake: 0.218287\n",
      "Epoch [59/100], d_loss: 0.627398, g_loss: 3.004781 D real: 0.812131, D fake: 0.182567\n",
      "Epoch [59/100], d_loss: 0.537114, g_loss: 2.407574 D real: 0.854460, D fake: 0.217396\n",
      "Epoch [60/100], d_loss: 0.599789, g_loss: 2.224455 D real: 0.802174, D fake: 0.170630\n",
      "Epoch [60/100], d_loss: 0.612904, g_loss: 2.915538 D real: 0.781334, D fake: 0.167928\n",
      "Epoch [60/100], d_loss: 0.636841, g_loss: 2.519794 D real: 0.788628, D fake: 0.191207\n",
      "Epoch [60/100], d_loss: 0.759947, g_loss: 2.011925 D real: 0.803976, D fake: 0.261446\n",
      "Epoch [61/100], d_loss: 0.405842, g_loss: 3.313656 D real: 0.848360, D fake: 0.131229\n",
      "Epoch [61/100], d_loss: 0.857491, g_loss: 2.367996 D real: 0.736413, D fake: 0.215629\n",
      "Epoch [61/100], d_loss: 0.648759, g_loss: 2.698263 D real: 0.837472, D fake: 0.229589\n",
      "Epoch [61/100], d_loss: 0.488929, g_loss: 2.733792 D real: 0.839248, D fake: 0.178411\n",
      "Epoch [62/100], d_loss: 0.825317, g_loss: 1.848014 D real: 0.745559, D fake: 0.250643\n",
      "Epoch [62/100], d_loss: 0.507134, g_loss: 2.734473 D real: 0.829636, D fake: 0.155726\n",
      "Epoch [62/100], d_loss: 0.741092, g_loss: 3.191331 D real: 0.791717, D fake: 0.248931\n",
      "Epoch [62/100], d_loss: 0.680199, g_loss: 3.225623 D real: 0.807817, D fake: 0.223095\n",
      "Epoch [63/100], d_loss: 0.548938, g_loss: 2.722121 D real: 0.840600, D fake: 0.195133\n",
      "Epoch [63/100], d_loss: 0.766736, g_loss: 2.205834 D real: 0.700072, D fake: 0.121538\n",
      "Epoch [63/100], d_loss: 0.590144, g_loss: 2.624034 D real: 0.869919, D fake: 0.265556\n",
      "Epoch [63/100], d_loss: 0.777667, g_loss: 1.954564 D real: 0.811448, D fake: 0.281388\n",
      "Epoch [64/100], d_loss: 0.719256, g_loss: 2.798090 D real: 0.726821, D fake: 0.117283\n",
      "Epoch [64/100], d_loss: 0.792579, g_loss: 2.783929 D real: 0.776272, D fake: 0.236634\n",
      "Epoch [64/100], d_loss: 0.455335, g_loss: 2.865624 D real: 0.834073, D fake: 0.164802\n",
      "Epoch [64/100], d_loss: 0.667266, g_loss: 2.043665 D real: 0.797241, D fake: 0.243762\n",
      "Epoch [65/100], d_loss: 0.723864, g_loss: 2.176561 D real: 0.736203, D fake: 0.162981\n",
      "Epoch [65/100], d_loss: 0.613090, g_loss: 2.224733 D real: 0.823299, D fake: 0.214245\n",
      "Epoch [65/100], d_loss: 0.459830, g_loss: 2.507310 D real: 0.887482, D fake: 0.175800\n",
      "Epoch [65/100], d_loss: 0.607792, g_loss: 1.956415 D real: 0.891958, D fake: 0.273637\n",
      "Epoch [66/100], d_loss: 0.716933, g_loss: 2.310570 D real: 0.737953, D fake: 0.119170\n",
      "Epoch [66/100], d_loss: 0.694967, g_loss: 1.998334 D real: 0.859318, D fake: 0.306935\n",
      "Epoch [66/100], d_loss: 0.528537, g_loss: 2.215004 D real: 0.833084, D fake: 0.208639\n",
      "Epoch [66/100], d_loss: 0.397528, g_loss: 3.071046 D real: 0.813179, D fake: 0.089649\n",
      "Epoch [67/100], d_loss: 0.479029, g_loss: 2.607611 D real: 0.892123, D fake: 0.206097\n",
      "Epoch [67/100], d_loss: 0.578312, g_loss: 2.393903 D real: 0.808985, D fake: 0.179744\n",
      "Epoch [67/100], d_loss: 0.783257, g_loss: 3.173243 D real: 0.723503, D fake: 0.147705\n",
      "Epoch [67/100], d_loss: 0.581908, g_loss: 2.186318 D real: 0.823278, D fake: 0.180797\n",
      "Epoch [68/100], d_loss: 0.559685, g_loss: 2.616211 D real: 0.784776, D fake: 0.137807\n",
      "Epoch [68/100], d_loss: 0.464099, g_loss: 2.873700 D real: 0.835546, D fake: 0.140562\n",
      "Epoch [68/100], d_loss: 0.614836, g_loss: 1.940872 D real: 0.821466, D fake: 0.201108\n",
      "Epoch [68/100], d_loss: 0.708276, g_loss: 1.783646 D real: 0.849165, D fake: 0.273684\n",
      "Epoch [69/100], d_loss: 0.749667, g_loss: 2.861450 D real: 0.741958, D fake: 0.203092\n",
      "Epoch [69/100], d_loss: 0.594811, g_loss: 2.554751 D real: 0.806331, D fake: 0.226365\n",
      "Epoch [69/100], d_loss: 0.566472, g_loss: 2.040482 D real: 0.798083, D fake: 0.183983\n",
      "Epoch [69/100], d_loss: 0.622981, g_loss: 2.442572 D real: 0.771780, D fake: 0.141618\n",
      "Epoch [70/100], d_loss: 0.727169, g_loss: 2.082708 D real: 0.754172, D fake: 0.233953\n",
      "Epoch [70/100], d_loss: 0.779887, g_loss: 2.036571 D real: 0.820946, D fake: 0.313511\n",
      "Epoch [70/100], d_loss: 0.888439, g_loss: 2.153292 D real: 0.777398, D fake: 0.299385\n",
      "Epoch [70/100], d_loss: 0.548069, g_loss: 2.445315 D real: 0.798533, D fake: 0.164235\n",
      "Epoch [71/100], d_loss: 0.758311, g_loss: 1.766824 D real: 0.786438, D fake: 0.288368\n",
      "Epoch [71/100], d_loss: 0.711961, g_loss: 2.279624 D real: 0.762182, D fake: 0.228672\n",
      "Epoch [71/100], d_loss: 0.855581, g_loss: 2.358886 D real: 0.705449, D fake: 0.158686\n",
      "Epoch [71/100], d_loss: 0.606695, g_loss: 2.436746 D real: 0.818386, D fake: 0.227569\n",
      "Epoch [72/100], d_loss: 0.871090, g_loss: 1.440289 D real: 0.765480, D fake: 0.280461\n",
      "Epoch [72/100], d_loss: 0.732443, g_loss: 2.433303 D real: 0.848630, D fake: 0.325889\n",
      "Epoch [72/100], d_loss: 0.674458, g_loss: 1.810264 D real: 0.773655, D fake: 0.224845\n",
      "Epoch [72/100], d_loss: 0.729825, g_loss: 2.020491 D real: 0.758972, D fake: 0.216842\n",
      "Epoch [73/100], d_loss: 0.763489, g_loss: 2.111477 D real: 0.722949, D fake: 0.197963\n",
      "Epoch [73/100], d_loss: 0.784883, g_loss: 2.550176 D real: 0.693592, D fake: 0.148928\n",
      "Epoch [73/100], d_loss: 0.637611, g_loss: 2.717460 D real: 0.775962, D fake: 0.201026\n",
      "Epoch [73/100], d_loss: 0.791640, g_loss: 1.823703 D real: 0.753398, D fake: 0.223175\n",
      "Epoch [74/100], d_loss: 0.899275, g_loss: 1.818531 D real: 0.716902, D fake: 0.260405\n",
      "Epoch [74/100], d_loss: 0.700155, g_loss: 2.177012 D real: 0.773090, D fake: 0.209289\n",
      "Epoch [74/100], d_loss: 0.765886, g_loss: 2.459244 D real: 0.717795, D fake: 0.139831\n",
      "Epoch [74/100], d_loss: 0.608662, g_loss: 2.125950 D real: 0.741806, D fake: 0.123888\n",
      "Epoch [75/100], d_loss: 0.771182, g_loss: 2.310492 D real: 0.787439, D fake: 0.234753\n",
      "Epoch [75/100], d_loss: 0.850480, g_loss: 2.410615 D real: 0.730250, D fake: 0.214504\n",
      "Epoch [75/100], d_loss: 0.730098, g_loss: 2.018748 D real: 0.715575, D fake: 0.154147\n",
      "Epoch [75/100], d_loss: 0.587241, g_loss: 2.137559 D real: 0.788529, D fake: 0.179688\n",
      "Epoch [76/100], d_loss: 0.804462, g_loss: 1.678782 D real: 0.737538, D fake: 0.248153\n",
      "Epoch [76/100], d_loss: 0.510627, g_loss: 2.668095 D real: 0.856295, D fake: 0.214810\n",
      "Epoch [76/100], d_loss: 0.619943, g_loss: 2.631513 D real: 0.817140, D fake: 0.212145\n",
      "Epoch [76/100], d_loss: 0.703075, g_loss: 2.072159 D real: 0.846939, D fake: 0.309577\n",
      "Epoch [77/100], d_loss: 0.846551, g_loss: 1.944405 D real: 0.757564, D fake: 0.244912\n",
      "Epoch [77/100], d_loss: 0.524010, g_loss: 2.229212 D real: 0.818120, D fake: 0.179998\n",
      "Epoch [77/100], d_loss: 0.591938, g_loss: 2.185005 D real: 0.815476, D fake: 0.194662\n",
      "Epoch [77/100], d_loss: 0.679231, g_loss: 2.622746 D real: 0.731429, D fake: 0.152336\n",
      "Epoch [78/100], d_loss: 0.770767, g_loss: 2.487301 D real: 0.728355, D fake: 0.206980\n",
      "Epoch [78/100], d_loss: 0.611746, g_loss: 2.686858 D real: 0.798378, D fake: 0.178465\n",
      "Epoch [78/100], d_loss: 0.718065, g_loss: 2.149711 D real: 0.818226, D fake: 0.271660\n",
      "Epoch [78/100], d_loss: 0.641887, g_loss: 1.737086 D real: 0.801761, D fake: 0.237263\n",
      "Epoch [79/100], d_loss: 0.649078, g_loss: 2.477037 D real: 0.839943, D fake: 0.259982\n",
      "Epoch [79/100], d_loss: 0.550616, g_loss: 2.529022 D real: 0.824955, D fake: 0.188219\n",
      "Epoch [79/100], d_loss: 0.628152, g_loss: 1.955962 D real: 0.810229, D fake: 0.237933\n",
      "Epoch [79/100], d_loss: 0.650972, g_loss: 2.258877 D real: 0.817924, D fake: 0.256762\n",
      "Epoch [80/100], d_loss: 0.648393, g_loss: 2.312071 D real: 0.744062, D fake: 0.171704\n",
      "Epoch [80/100], d_loss: 0.871945, g_loss: 2.468450 D real: 0.675379, D fake: 0.168709\n",
      "Epoch [80/100], d_loss: 0.826711, g_loss: 2.164632 D real: 0.709325, D fake: 0.178366\n",
      "Epoch [80/100], d_loss: 0.716650, g_loss: 2.207366 D real: 0.718582, D fake: 0.153721\n",
      "Epoch [81/100], d_loss: 0.739961, g_loss: 2.419457 D real: 0.745942, D fake: 0.224080\n",
      "Epoch [81/100], d_loss: 0.909346, g_loss: 1.741308 D real: 0.712899, D fake: 0.250770\n",
      "Epoch [81/100], d_loss: 0.650035, g_loss: 2.261340 D real: 0.768693, D fake: 0.192326\n",
      "Epoch [81/100], d_loss: 0.629730, g_loss: 2.730726 D real: 0.792102, D fake: 0.188504\n",
      "Epoch [82/100], d_loss: 0.755648, g_loss: 2.004925 D real: 0.753804, D fake: 0.210708\n",
      "Epoch [82/100], d_loss: 0.565304, g_loss: 1.844435 D real: 0.797283, D fake: 0.193899\n",
      "Epoch [82/100], d_loss: 0.655473, g_loss: 1.902054 D real: 0.759591, D fake: 0.196421\n",
      "Epoch [82/100], d_loss: 0.596147, g_loss: 2.313469 D real: 0.852131, D fake: 0.270993\n",
      "Epoch [83/100], d_loss: 0.630260, g_loss: 1.734469 D real: 0.794948, D fake: 0.211233\n",
      "Epoch [83/100], d_loss: 0.773880, g_loss: 1.792245 D real: 0.762420, D fake: 0.249026\n",
      "Epoch [83/100], d_loss: 0.731307, g_loss: 2.281614 D real: 0.714351, D fake: 0.183919\n",
      "Epoch [83/100], d_loss: 0.775756, g_loss: 2.316989 D real: 0.805622, D fake: 0.309471\n",
      "Epoch [84/100], d_loss: 0.922186, g_loss: 1.764933 D real: 0.629747, D fake: 0.179840\n",
      "Epoch [84/100], d_loss: 0.883982, g_loss: 1.715718 D real: 0.680735, D fake: 0.211745\n",
      "Epoch [84/100], d_loss: 0.833792, g_loss: 2.097772 D real: 0.720718, D fake: 0.214013\n",
      "Epoch [84/100], d_loss: 0.721276, g_loss: 2.148111 D real: 0.794537, D fake: 0.266255\n",
      "Epoch [85/100], d_loss: 0.804129, g_loss: 2.510051 D real: 0.730887, D fake: 0.219495\n",
      "Epoch [85/100], d_loss: 0.703311, g_loss: 1.972364 D real: 0.788234, D fake: 0.251402\n",
      "Epoch [85/100], d_loss: 0.793545, g_loss: 2.441565 D real: 0.739888, D fake: 0.227474\n",
      "Epoch [85/100], d_loss: 0.817873, g_loss: 2.507940 D real: 0.664641, D fake: 0.144348\n",
      "Epoch [86/100], d_loss: 0.784433, g_loss: 1.763434 D real: 0.786250, D fake: 0.285564\n",
      "Epoch [86/100], d_loss: 0.703581, g_loss: 1.762983 D real: 0.720758, D fake: 0.193561\n",
      "Epoch [86/100], d_loss: 0.907024, g_loss: 2.100676 D real: 0.651763, D fake: 0.200696\n",
      "Epoch [86/100], d_loss: 0.785539, g_loss: 1.963431 D real: 0.762590, D fake: 0.285742\n",
      "Epoch [87/100], d_loss: 0.653298, g_loss: 1.637700 D real: 0.773934, D fake: 0.228358\n",
      "Epoch [87/100], d_loss: 0.641949, g_loss: 2.070234 D real: 0.765869, D fake: 0.214116\n",
      "Epoch [87/100], d_loss: 0.803759, g_loss: 1.928517 D real: 0.744299, D fake: 0.211519\n",
      "Epoch [87/100], d_loss: 0.604821, g_loss: 2.113853 D real: 0.780412, D fake: 0.191206\n",
      "Epoch [88/100], d_loss: 0.672603, g_loss: 1.810413 D real: 0.811248, D fake: 0.274909\n",
      "Epoch [88/100], d_loss: 0.870171, g_loss: 1.457544 D real: 0.821968, D fake: 0.336372\n",
      "Epoch [88/100], d_loss: 0.854059, g_loss: 2.163908 D real: 0.754425, D fake: 0.280057\n",
      "Epoch [88/100], d_loss: 0.752078, g_loss: 1.451716 D real: 0.755003, D fake: 0.231848\n",
      "Epoch [89/100], d_loss: 0.827652, g_loss: 2.324834 D real: 0.807607, D fake: 0.320582\n",
      "Epoch [89/100], d_loss: 0.812567, g_loss: 2.292133 D real: 0.756420, D fake: 0.232477\n",
      "Epoch [89/100], d_loss: 0.764653, g_loss: 2.016103 D real: 0.721278, D fake: 0.212802\n",
      "Epoch [89/100], d_loss: 0.909387, g_loss: 2.222899 D real: 0.703530, D fake: 0.224746\n",
      "Epoch [90/100], d_loss: 0.768132, g_loss: 1.807232 D real: 0.724768, D fake: 0.230149\n",
      "Epoch [90/100], d_loss: 0.999530, g_loss: 1.941215 D real: 0.665043, D fake: 0.238217\n",
      "Epoch [90/100], d_loss: 0.707862, g_loss: 2.135833 D real: 0.760153, D fake: 0.237250\n",
      "Epoch [90/100], d_loss: 0.791284, g_loss: 1.871231 D real: 0.732405, D fake: 0.236599\n",
      "Epoch [91/100], d_loss: 0.722623, g_loss: 2.029155 D real: 0.759689, D fake: 0.231615\n",
      "Epoch [91/100], d_loss: 0.899017, g_loss: 1.816979 D real: 0.756571, D fake: 0.300345\n",
      "Epoch [91/100], d_loss: 0.761116, g_loss: 2.452075 D real: 0.745022, D fake: 0.229425\n",
      "Epoch [91/100], d_loss: 1.074556, g_loss: 1.878394 D real: 0.750171, D fake: 0.389258\n",
      "Epoch [92/100], d_loss: 0.660248, g_loss: 2.065587 D real: 0.795052, D fake: 0.237279\n",
      "Epoch [92/100], d_loss: 0.836928, g_loss: 1.991436 D real: 0.754141, D fake: 0.282737\n",
      "Epoch [92/100], d_loss: 0.697282, g_loss: 1.783074 D real: 0.811236, D fake: 0.260835\n",
      "Epoch [92/100], d_loss: 0.682039, g_loss: 2.440367 D real: 0.747753, D fake: 0.215865\n",
      "Epoch [93/100], d_loss: 0.832379, g_loss: 1.962502 D real: 0.695869, D fake: 0.197166\n",
      "Epoch [93/100], d_loss: 0.963496, g_loss: 1.781554 D real: 0.786392, D fake: 0.353269\n",
      "Epoch [93/100], d_loss: 0.761403, g_loss: 2.433113 D real: 0.679463, D fake: 0.158548\n",
      "Epoch [93/100], d_loss: 0.711650, g_loss: 2.158125 D real: 0.754797, D fake: 0.219619\n",
      "Epoch [94/100], d_loss: 0.827985, g_loss: 1.804227 D real: 0.749975, D fake: 0.296412\n",
      "Epoch [94/100], d_loss: 0.741592, g_loss: 1.763207 D real: 0.740243, D fake: 0.235284\n",
      "Epoch [94/100], d_loss: 0.668729, g_loss: 1.837322 D real: 0.751544, D fake: 0.205667\n",
      "Epoch [94/100], d_loss: 0.945259, g_loss: 1.696775 D real: 0.676169, D fake: 0.264611\n",
      "Epoch [95/100], d_loss: 0.872346, g_loss: 2.113094 D real: 0.718914, D fake: 0.237448\n",
      "Epoch [95/100], d_loss: 0.802793, g_loss: 1.925325 D real: 0.842203, D fake: 0.377221\n",
      "Epoch [95/100], d_loss: 0.929543, g_loss: 1.695875 D real: 0.708649, D fake: 0.268696\n",
      "Epoch [95/100], d_loss: 1.081274, g_loss: 2.233922 D real: 0.715321, D fake: 0.348862\n",
      "Epoch [96/100], d_loss: 0.749267, g_loss: 1.703199 D real: 0.712661, D fake: 0.198519\n",
      "Epoch [96/100], d_loss: 0.753497, g_loss: 1.625480 D real: 0.726365, D fake: 0.248089\n",
      "Epoch [96/100], d_loss: 0.958481, g_loss: 1.522923 D real: 0.707078, D fake: 0.298186\n",
      "Epoch [96/100], d_loss: 0.849554, g_loss: 2.093447 D real: 0.672724, D fake: 0.204149\n",
      "Epoch [97/100], d_loss: 0.791382, g_loss: 1.837663 D real: 0.690354, D fake: 0.198904\n",
      "Epoch [97/100], d_loss: 0.779058, g_loss: 1.960461 D real: 0.727757, D fake: 0.241791\n",
      "Epoch [97/100], d_loss: 0.751987, g_loss: 1.983324 D real: 0.833568, D fake: 0.307700\n",
      "Epoch [97/100], d_loss: 0.698661, g_loss: 1.876003 D real: 0.856811, D fake: 0.343283\n",
      "Epoch [98/100], d_loss: 0.874313, g_loss: 2.058804 D real: 0.795648, D fake: 0.326389\n",
      "Epoch [98/100], d_loss: 0.584067, g_loss: 1.821533 D real: 0.810946, D fake: 0.242129\n",
      "Epoch [98/100], d_loss: 0.681508, g_loss: 1.966577 D real: 0.746452, D fake: 0.192236\n",
      "Epoch [98/100], d_loss: 0.900376, g_loss: 1.581680 D real: 0.709046, D fake: 0.292062\n",
      "Epoch [99/100], d_loss: 0.963614, g_loss: 2.026332 D real: 0.745315, D fake: 0.339384\n",
      "Epoch [99/100], d_loss: 0.952706, g_loss: 1.752511 D real: 0.796838, D fake: 0.392039\n",
      "Epoch [99/100], d_loss: 0.760297, g_loss: 2.022799 D real: 0.711863, D fake: 0.205936\n",
      "Epoch [99/100], d_loss: 0.911005, g_loss: 2.209376 D real: 0.667140, D fake: 0.221385\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epoches):\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # =================train discriminator\n",
    "        img = img.view(num_img, -1)\n",
    "        real_img = img.to(device)\n",
    "        real_label = torch.ones(num_img).to(device)\n",
    "        fake_label = torch.zeros(num_img).to(device)\n",
    "        \n",
    "        # compute loss of real_img\n",
    "        real_out = D(real_img)\n",
    "        d_loss_real = criterion(real_out, real_label)\n",
    "        real_scores = real_out  # closer to 1 means better\n",
    "\n",
    "        # compute loss of fake_img\n",
    "        z = torch.randn(num_img, z_dimension).to(device)\n",
    "        fake_img = G(z)\n",
    "        fake_out = D(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out  # closer to 0 means better\n",
    "\n",
    "        # bp and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # ===============train generator\n",
    "        # compute loss of fake_img\n",
    "        z = torch.randn(num_img, z_dimension).to(device)\n",
    "        fake_img = G(z)\n",
    "        output = D(fake_img)\n",
    "        g_loss = criterion(output, real_label)\n",
    "\n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epoches}], d_loss: {d_loss:.6f}, g_loss: {g_loss:.6f}',\n",
    "                  f'D real: {real_scores.mean():.6f}, D fake: {fake_scores.mean():.6f}')\n",
    "    if epoch == 0:\n",
    "        real_images = to_img(real_img)\n",
    "        save_image(real_images, 'save/sim_gan/real_images.png')\n",
    "\n",
    "    fake_images = to_img(fake_img)\n",
    "    save_image(fake_images, f'save/sim_gan/fake_images-{epoch+1:0>3d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), 'save/sim_gan/generator.pytorch')\n",
    "torch.save(D.state_dict(), 'save/sim_gan/discriminator.pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
