{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # whether GPU is supportted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用手写数字训练集 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='../_data/mnist', train=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='../_data/mnist', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义简单的前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuralnetwork(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Neuralnetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neuralnetwork(28 * 28, 300, 100, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n",
      "[1/50] Loss: 1.986846, Acc: 0.541146\n",
      "[1/50] Loss: 1.531218, Acc: 0.646563\n",
      "[1/50] Loss: 1.239183, Acc: 0.709028\n",
      "[1/50] Loss: 1.057312, Acc: 0.746484\n",
      "[1/50] Loss: 0.938950, Acc: 0.771604\n",
      "[1/50] Loss: 0.851509, Acc: 0.790816\n",
      "Finish 1 epoch, Loss: 0.834077, Acc: 0.794667\n",
      "Test Loss: 0.381832, Acc: 0.890600\n",
      "epoch 2\n",
      "**********\n",
      "[2/50] Loss: 0.388355, Acc: 0.890833\n",
      "[2/50] Loss: 0.376780, Acc: 0.893281\n",
      "[2/50] Loss: 0.373105, Acc: 0.892986\n",
      "[2/50] Loss: 0.369161, Acc: 0.894219\n",
      "[2/50] Loss: 0.364348, Acc: 0.895187\n",
      "[2/50] Loss: 0.361194, Acc: 0.896510\n",
      "Finish 2 epoch, Loss: 0.360858, Acc: 0.896817\n",
      "Test Loss: 0.317618, Acc: 0.910300\n",
      "epoch 3\n",
      "**********\n",
      "[3/50] Loss: 0.315339, Acc: 0.910208\n",
      "[3/50] Loss: 0.323710, Acc: 0.905677\n",
      "[3/50] Loss: 0.326917, Acc: 0.905208\n",
      "[3/50] Loss: 0.330085, Acc: 0.905313\n",
      "[3/50] Loss: 0.326259, Acc: 0.905896\n",
      "[3/50] Loss: 0.324008, Acc: 0.907257\n",
      "Finish 3 epoch, Loss: 0.322596, Acc: 0.907567\n",
      "Test Loss: 0.300608, Acc: 0.914300\n",
      "epoch 4\n",
      "**********\n",
      "[4/50] Loss: 0.307686, Acc: 0.917396\n",
      "[4/50] Loss: 0.318392, Acc: 0.912240\n",
      "[4/50] Loss: 0.309723, Acc: 0.913403\n",
      "[4/50] Loss: 0.308681, Acc: 0.912682\n",
      "[4/50] Loss: 0.307788, Acc: 0.912479\n",
      "[4/50] Loss: 0.306704, Acc: 0.912951\n",
      "Finish 4 epoch, Loss: 0.305846, Acc: 0.913217\n",
      "Test Loss: 0.288255, Acc: 0.918300\n",
      "epoch 5\n",
      "**********\n",
      "[5/50] Loss: 0.286275, Acc: 0.919479\n",
      "[5/50] Loss: 0.291349, Acc: 0.917656\n",
      "[5/50] Loss: 0.289621, Acc: 0.917535\n",
      "[5/50] Loss: 0.294513, Acc: 0.917109\n",
      "[5/50] Loss: 0.294615, Acc: 0.916812\n",
      "[5/50] Loss: 0.295673, Acc: 0.916372\n",
      "Finish 5 epoch, Loss: 0.295851, Acc: 0.916150\n",
      "Test Loss: 0.283614, Acc: 0.919300\n",
      "epoch 6\n",
      "**********\n",
      "[6/50] Loss: 0.300489, Acc: 0.913958\n",
      "[6/50] Loss: 0.291140, Acc: 0.917500\n",
      "[6/50] Loss: 0.292905, Acc: 0.916424\n",
      "[6/50] Loss: 0.296285, Acc: 0.916328\n",
      "[6/50] Loss: 0.291977, Acc: 0.917687\n",
      "[6/50] Loss: 0.288437, Acc: 0.918351\n",
      "Finish 6 epoch, Loss: 0.288615, Acc: 0.918283\n",
      "Test Loss: 0.278767, Acc: 0.919500\n",
      "epoch 7\n",
      "**********\n",
      "[7/50] Loss: 0.278031, Acc: 0.920417\n",
      "[7/50] Loss: 0.284016, Acc: 0.919375\n",
      "[7/50] Loss: 0.281349, Acc: 0.920660\n",
      "[7/50] Loss: 0.281972, Acc: 0.920000\n",
      "[7/50] Loss: 0.283876, Acc: 0.919583\n",
      "[7/50] Loss: 0.284970, Acc: 0.919618\n",
      "Finish 7 epoch, Loss: 0.283500, Acc: 0.920067\n",
      "Test Loss: 0.276602, Acc: 0.921300\n",
      "epoch 8\n",
      "**********\n",
      "[8/50] Loss: 0.288105, Acc: 0.918646\n",
      "[8/50] Loss: 0.278431, Acc: 0.920885\n",
      "[8/50] Loss: 0.278048, Acc: 0.921632\n",
      "[8/50] Loss: 0.275509, Acc: 0.921823\n",
      "[8/50] Loss: 0.277689, Acc: 0.921625\n",
      "[8/50] Loss: 0.278661, Acc: 0.921302\n",
      "Finish 8 epoch, Loss: 0.279765, Acc: 0.921250\n",
      "Test Loss: 0.279267, Acc: 0.921400\n",
      "epoch 9\n",
      "**********\n",
      "[9/50] Loss: 0.266038, Acc: 0.926250\n",
      "[9/50] Loss: 0.272900, Acc: 0.922552\n",
      "[9/50] Loss: 0.274848, Acc: 0.923507\n",
      "[9/50] Loss: 0.276246, Acc: 0.922786\n",
      "[9/50] Loss: 0.277066, Acc: 0.922583\n",
      "[9/50] Loss: 0.277217, Acc: 0.922465\n",
      "Finish 9 epoch, Loss: 0.276677, Acc: 0.922633\n",
      "Test Loss: 0.272497, Acc: 0.922300\n",
      "epoch 10\n",
      "**********\n",
      "[10/50] Loss: 0.269968, Acc: 0.923958\n",
      "[10/50] Loss: 0.273255, Acc: 0.923021\n",
      "[10/50] Loss: 0.270328, Acc: 0.924167\n",
      "[10/50] Loss: 0.272908, Acc: 0.923151\n",
      "[10/50] Loss: 0.273857, Acc: 0.923042\n",
      "[10/50] Loss: 0.273744, Acc: 0.923194\n",
      "Finish 10 epoch, Loss: 0.273982, Acc: 0.923117\n",
      "Test Loss: 0.271349, Acc: 0.922800\n",
      "epoch 11\n",
      "**********\n",
      "[11/50] Loss: 0.278123, Acc: 0.924271\n",
      "[11/50] Loss: 0.283321, Acc: 0.921667\n",
      "[11/50] Loss: 0.278631, Acc: 0.922847\n",
      "[11/50] Loss: 0.274596, Acc: 0.923385\n",
      "[11/50] Loss: 0.273755, Acc: 0.923354\n",
      "[11/50] Loss: 0.272863, Acc: 0.923316\n",
      "Finish 11 epoch, Loss: 0.271230, Acc: 0.923617\n",
      "Test Loss: 0.272592, Acc: 0.924200\n",
      "epoch 12\n",
      "**********\n",
      "[12/50] Loss: 0.258295, Acc: 0.929063\n",
      "[12/50] Loss: 0.265518, Acc: 0.927031\n",
      "[12/50] Loss: 0.268012, Acc: 0.924931\n",
      "[12/50] Loss: 0.268840, Acc: 0.925313\n",
      "[12/50] Loss: 0.267168, Acc: 0.925583\n",
      "[12/50] Loss: 0.268571, Acc: 0.925156\n",
      "Finish 12 epoch, Loss: 0.269003, Acc: 0.925150\n",
      "Test Loss: 0.268815, Acc: 0.924600\n",
      "epoch 13\n",
      "**********\n",
      "[13/50] Loss: 0.269696, Acc: 0.926354\n",
      "[13/50] Loss: 0.263214, Acc: 0.926823\n",
      "[13/50] Loss: 0.263401, Acc: 0.926563\n",
      "[13/50] Loss: 0.266457, Acc: 0.926016\n",
      "[13/50] Loss: 0.267681, Acc: 0.925687\n",
      "[13/50] Loss: 0.267277, Acc: 0.925677\n",
      "Finish 13 epoch, Loss: 0.267349, Acc: 0.925533\n",
      "Test Loss: 0.272416, Acc: 0.920900\n",
      "epoch 14\n",
      "**********\n",
      "[14/50] Loss: 0.274034, Acc: 0.923750\n",
      "[14/50] Loss: 0.267492, Acc: 0.925573\n",
      "[14/50] Loss: 0.265127, Acc: 0.926528\n",
      "[14/50] Loss: 0.267547, Acc: 0.925938\n",
      "[14/50] Loss: 0.265294, Acc: 0.926292\n",
      "[14/50] Loss: 0.265710, Acc: 0.926059\n",
      "Finish 14 epoch, Loss: 0.265744, Acc: 0.926000\n",
      "Test Loss: 0.276712, Acc: 0.923200\n",
      "epoch 15\n",
      "**********\n",
      "[15/50] Loss: 0.262072, Acc: 0.924063\n",
      "[15/50] Loss: 0.263136, Acc: 0.924688\n",
      "[15/50] Loss: 0.263673, Acc: 0.925660\n",
      "[15/50] Loss: 0.261044, Acc: 0.926302\n",
      "[15/50] Loss: 0.262778, Acc: 0.926125\n",
      "[15/50] Loss: 0.265565, Acc: 0.925903\n",
      "Finish 15 epoch, Loss: 0.264963, Acc: 0.926150\n",
      "Test Loss: 0.268712, Acc: 0.922400\n",
      "epoch 16\n",
      "**********\n",
      "[16/50] Loss: 0.260660, Acc: 0.928958\n",
      "[16/50] Loss: 0.259756, Acc: 0.929479\n",
      "[16/50] Loss: 0.265019, Acc: 0.927639\n",
      "[16/50] Loss: 0.262566, Acc: 0.928021\n",
      "[16/50] Loss: 0.262207, Acc: 0.927250\n",
      "[16/50] Loss: 0.262394, Acc: 0.927431\n",
      "Finish 16 epoch, Loss: 0.262835, Acc: 0.927167\n",
      "Test Loss: 0.269274, Acc: 0.924800\n",
      "epoch 17\n",
      "**********\n",
      "[17/50] Loss: 0.256594, Acc: 0.929583\n",
      "[17/50] Loss: 0.251631, Acc: 0.930729\n",
      "[17/50] Loss: 0.254811, Acc: 0.929236\n",
      "[17/50] Loss: 0.259232, Acc: 0.927552\n",
      "[17/50] Loss: 0.260069, Acc: 0.927583\n",
      "[17/50] Loss: 0.262238, Acc: 0.927170\n",
      "Finish 17 epoch, Loss: 0.261976, Acc: 0.927267\n",
      "Test Loss: 0.268579, Acc: 0.923800\n",
      "epoch 18\n",
      "**********\n",
      "[18/50] Loss: 0.266715, Acc: 0.929688\n",
      "[18/50] Loss: 0.272703, Acc: 0.925104\n",
      "[18/50] Loss: 0.266367, Acc: 0.926458\n",
      "[18/50] Loss: 0.265831, Acc: 0.925990\n",
      "[18/50] Loss: 0.264563, Acc: 0.926208\n",
      "[18/50] Loss: 0.261661, Acc: 0.927118\n",
      "Finish 18 epoch, Loss: 0.260942, Acc: 0.927050\n",
      "Test Loss: 0.268560, Acc: 0.925500\n",
      "epoch 19\n",
      "**********\n",
      "[19/50] Loss: 0.254125, Acc: 0.924896\n",
      "[19/50] Loss: 0.256565, Acc: 0.927292\n",
      "[19/50] Loss: 0.259505, Acc: 0.927361\n",
      "[19/50] Loss: 0.261593, Acc: 0.926458\n",
      "[19/50] Loss: 0.259223, Acc: 0.927792\n",
      "[19/50] Loss: 0.260277, Acc: 0.927899\n",
      "Finish 19 epoch, Loss: 0.259948, Acc: 0.928117\n",
      "Test Loss: 0.271178, Acc: 0.922900\n",
      "epoch 20\n",
      "**********\n",
      "[20/50] Loss: 0.259023, Acc: 0.928125\n",
      "[20/50] Loss: 0.260381, Acc: 0.927760\n",
      "[20/50] Loss: 0.262137, Acc: 0.928993\n",
      "[20/50] Loss: 0.260519, Acc: 0.929115\n",
      "[20/50] Loss: 0.259367, Acc: 0.928917\n",
      "[20/50] Loss: 0.258856, Acc: 0.929184\n",
      "Finish 20 epoch, Loss: 0.258905, Acc: 0.929317\n",
      "Test Loss: 0.271513, Acc: 0.924400\n",
      "epoch 21\n",
      "**********\n",
      "[21/50] Loss: 0.256200, Acc: 0.930208\n",
      "[21/50] Loss: 0.258476, Acc: 0.929427\n",
      "[21/50] Loss: 0.256937, Acc: 0.928715\n",
      "[21/50] Loss: 0.256391, Acc: 0.929089\n",
      "[21/50] Loss: 0.259000, Acc: 0.928250\n",
      "[21/50] Loss: 0.258172, Acc: 0.928212\n",
      "Finish 21 epoch, Loss: 0.257601, Acc: 0.928150\n",
      "Test Loss: 0.270426, Acc: 0.923800\n",
      "epoch 22\n",
      "**********\n",
      "[22/50] Loss: 0.251648, Acc: 0.930833\n",
      "[22/50] Loss: 0.253012, Acc: 0.929531\n",
      "[22/50] Loss: 0.255103, Acc: 0.929792\n",
      "[22/50] Loss: 0.255789, Acc: 0.929349\n",
      "[22/50] Loss: 0.259544, Acc: 0.927917\n",
      "[22/50] Loss: 0.256972, Acc: 0.928368\n",
      "Finish 22 epoch, Loss: 0.257047, Acc: 0.928500\n",
      "Test Loss: 0.266290, Acc: 0.924700\n",
      "epoch 23\n",
      "**********\n",
      "[23/50] Loss: 0.261720, Acc: 0.929792\n",
      "[23/50] Loss: 0.256225, Acc: 0.930781\n",
      "[23/50] Loss: 0.255803, Acc: 0.929514\n",
      "[23/50] Loss: 0.255183, Acc: 0.929271\n",
      "[23/50] Loss: 0.254195, Acc: 0.929625\n",
      "[23/50] Loss: 0.256880, Acc: 0.929323\n",
      "Finish 23 epoch, Loss: 0.255787, Acc: 0.929467\n",
      "Test Loss: 0.279276, Acc: 0.922000\n",
      "epoch 24\n",
      "**********\n",
      "[24/50] Loss: 0.271481, Acc: 0.928229\n",
      "[24/50] Loss: 0.261444, Acc: 0.929479\n",
      "[24/50] Loss: 0.261800, Acc: 0.928819\n",
      "[24/50] Loss: 0.257858, Acc: 0.929635\n",
      "[24/50] Loss: 0.258101, Acc: 0.929521\n",
      "[24/50] Loss: 0.256008, Acc: 0.929705\n",
      "Finish 24 epoch, Loss: 0.255595, Acc: 0.929617\n",
      "Test Loss: 0.275646, Acc: 0.921800\n",
      "epoch 25\n",
      "**********\n",
      "[25/50] Loss: 0.253743, Acc: 0.929479\n",
      "[25/50] Loss: 0.252481, Acc: 0.930260\n",
      "[25/50] Loss: 0.250188, Acc: 0.930104\n",
      "[25/50] Loss: 0.248486, Acc: 0.930391\n",
      "[25/50] Loss: 0.252037, Acc: 0.930208\n",
      "[25/50] Loss: 0.252827, Acc: 0.930035\n",
      "Finish 25 epoch, Loss: 0.254574, Acc: 0.929800\n",
      "Test Loss: 0.272700, Acc: 0.925000\n",
      "epoch 26\n",
      "**********\n",
      "[26/50] Loss: 0.260594, Acc: 0.927188\n",
      "[26/50] Loss: 0.255144, Acc: 0.929688\n",
      "[26/50] Loss: 0.254186, Acc: 0.929375\n",
      "[26/50] Loss: 0.253979, Acc: 0.929193\n",
      "[26/50] Loss: 0.255188, Acc: 0.928937\n",
      "[26/50] Loss: 0.254801, Acc: 0.929497\n",
      "Finish 26 epoch, Loss: 0.253992, Acc: 0.929733\n",
      "Test Loss: 0.270242, Acc: 0.924500\n",
      "epoch 27\n",
      "**********\n",
      "[27/50] Loss: 0.253341, Acc: 0.927813\n",
      "[27/50] Loss: 0.250509, Acc: 0.929063\n",
      "[27/50] Loss: 0.250877, Acc: 0.929722\n",
      "[27/50] Loss: 0.253051, Acc: 0.928854\n",
      "[27/50] Loss: 0.251998, Acc: 0.929750\n",
      "[27/50] Loss: 0.253322, Acc: 0.929635\n",
      "Finish 27 epoch, Loss: 0.253951, Acc: 0.929467\n",
      "Test Loss: 0.267520, Acc: 0.927100\n",
      "epoch 28\n",
      "**********\n",
      "[28/50] Loss: 0.245354, Acc: 0.933750\n",
      "[28/50] Loss: 0.247722, Acc: 0.932187\n",
      "[28/50] Loss: 0.248494, Acc: 0.932118\n",
      "[28/50] Loss: 0.247320, Acc: 0.932057\n",
      "[28/50] Loss: 0.250281, Acc: 0.931250\n",
      "[28/50] Loss: 0.252586, Acc: 0.930417\n",
      "Finish 28 epoch, Loss: 0.252563, Acc: 0.930283\n",
      "Test Loss: 0.278833, Acc: 0.922900\n",
      "epoch 29\n",
      "**********\n",
      "[29/50] Loss: 0.233874, Acc: 0.932396\n",
      "[29/50] Loss: 0.240188, Acc: 0.931615\n",
      "[29/50] Loss: 0.244496, Acc: 0.930868\n",
      "[29/50] Loss: 0.246858, Acc: 0.930391\n",
      "[29/50] Loss: 0.247337, Acc: 0.931146\n",
      "[29/50] Loss: 0.251526, Acc: 0.930069\n",
      "Finish 29 epoch, Loss: 0.252672, Acc: 0.929867\n",
      "Test Loss: 0.268378, Acc: 0.924300\n",
      "epoch 30\n",
      "**********\n",
      "[30/50] Loss: 0.266089, Acc: 0.926979\n",
      "[30/50] Loss: 0.247982, Acc: 0.930573\n",
      "[30/50] Loss: 0.252174, Acc: 0.930486\n",
      "[30/50] Loss: 0.251794, Acc: 0.930990\n",
      "[30/50] Loss: 0.250991, Acc: 0.930917\n",
      "[30/50] Loss: 0.251476, Acc: 0.930469\n",
      "Finish 30 epoch, Loss: 0.251456, Acc: 0.930400\n",
      "Test Loss: 0.271350, Acc: 0.924600\n",
      "epoch 31\n",
      "**********\n",
      "[31/50] Loss: 0.240958, Acc: 0.930208\n",
      "[31/50] Loss: 0.250952, Acc: 0.929375\n",
      "[31/50] Loss: 0.248972, Acc: 0.930972\n",
      "[31/50] Loss: 0.251654, Acc: 0.929896\n",
      "[31/50] Loss: 0.251680, Acc: 0.930313\n",
      "[31/50] Loss: 0.251681, Acc: 0.930000\n",
      "Finish 31 epoch, Loss: 0.251278, Acc: 0.930083\n",
      "Test Loss: 0.270330, Acc: 0.925800\n",
      "epoch 32\n",
      "**********\n",
      "[32/50] Loss: 0.259333, Acc: 0.930104\n",
      "[32/50] Loss: 0.261568, Acc: 0.928750\n",
      "[32/50] Loss: 0.258700, Acc: 0.928368\n",
      "[32/50] Loss: 0.252794, Acc: 0.930495\n",
      "[32/50] Loss: 0.249820, Acc: 0.931000\n",
      "[32/50] Loss: 0.251268, Acc: 0.930538\n",
      "Finish 32 epoch, Loss: 0.250680, Acc: 0.930700\n",
      "Test Loss: 0.269339, Acc: 0.925600\n",
      "epoch 33\n",
      "**********\n",
      "[33/50] Loss: 0.250450, Acc: 0.929688\n",
      "[33/50] Loss: 0.247763, Acc: 0.931042\n",
      "[33/50] Loss: 0.248968, Acc: 0.931215\n",
      "[33/50] Loss: 0.248834, Acc: 0.931432\n",
      "[33/50] Loss: 0.250432, Acc: 0.931104\n",
      "[33/50] Loss: 0.249856, Acc: 0.931042\n",
      "Finish 33 epoch, Loss: 0.250541, Acc: 0.931133\n",
      "Test Loss: 0.270242, Acc: 0.926000\n",
      "epoch 34\n",
      "**********\n",
      "[34/50] Loss: 0.242659, Acc: 0.931354\n",
      "[34/50] Loss: 0.244008, Acc: 0.932187\n",
      "[34/50] Loss: 0.249534, Acc: 0.930035\n",
      "[34/50] Loss: 0.246097, Acc: 0.930703\n",
      "[34/50] Loss: 0.247731, Acc: 0.930583\n",
      "[34/50] Loss: 0.250093, Acc: 0.930260\n",
      "Finish 34 epoch, Loss: 0.249918, Acc: 0.930483\n",
      "Test Loss: 0.270068, Acc: 0.924900\n",
      "epoch 35\n",
      "**********\n",
      "[35/50] Loss: 0.243355, Acc: 0.932708\n",
      "[35/50] Loss: 0.251290, Acc: 0.931354\n",
      "[35/50] Loss: 0.250715, Acc: 0.931146\n",
      "[35/50] Loss: 0.250371, Acc: 0.930703\n",
      "[35/50] Loss: 0.248934, Acc: 0.930687\n",
      "[35/50] Loss: 0.249215, Acc: 0.930816\n",
      "Finish 35 epoch, Loss: 0.249517, Acc: 0.930850\n",
      "Test Loss: 0.267793, Acc: 0.925200\n",
      "epoch 36\n",
      "**********\n",
      "[36/50] Loss: 0.225005, Acc: 0.934271\n",
      "[36/50] Loss: 0.241251, Acc: 0.931406\n",
      "[36/50] Loss: 0.242904, Acc: 0.931597\n",
      "[36/50] Loss: 0.243722, Acc: 0.932031\n",
      "[36/50] Loss: 0.248524, Acc: 0.931063\n",
      "[36/50] Loss: 0.248144, Acc: 0.931198\n",
      "Finish 36 epoch, Loss: 0.248771, Acc: 0.931467\n",
      "Test Loss: 0.267909, Acc: 0.925300\n",
      "epoch 37\n",
      "**********\n",
      "[37/50] Loss: 0.243746, Acc: 0.932917\n",
      "[37/50] Loss: 0.244641, Acc: 0.932396\n",
      "[37/50] Loss: 0.245258, Acc: 0.931910\n",
      "[37/50] Loss: 0.244800, Acc: 0.932292\n",
      "[37/50] Loss: 0.248339, Acc: 0.931687\n",
      "[37/50] Loss: 0.248280, Acc: 0.931181\n",
      "Finish 37 epoch, Loss: 0.248682, Acc: 0.931083\n",
      "Test Loss: 0.270239, Acc: 0.925500\n",
      "epoch 38\n",
      "**********\n",
      "[38/50] Loss: 0.247703, Acc: 0.930833\n",
      "[38/50] Loss: 0.243805, Acc: 0.932708\n",
      "[38/50] Loss: 0.243182, Acc: 0.932882\n",
      "[38/50] Loss: 0.245306, Acc: 0.931901\n",
      "[38/50] Loss: 0.245233, Acc: 0.931917\n",
      "[38/50] Loss: 0.247607, Acc: 0.931076\n",
      "Finish 38 epoch, Loss: 0.248137, Acc: 0.930833\n",
      "Test Loss: 0.270657, Acc: 0.923200\n",
      "epoch 39\n",
      "**********\n",
      "[39/50] Loss: 0.250566, Acc: 0.930104\n",
      "[39/50] Loss: 0.248249, Acc: 0.931042\n",
      "[39/50] Loss: 0.250512, Acc: 0.931007\n",
      "[39/50] Loss: 0.248591, Acc: 0.930807\n",
      "[39/50] Loss: 0.247927, Acc: 0.930958\n",
      "[39/50] Loss: 0.247983, Acc: 0.930885\n",
      "Finish 39 epoch, Loss: 0.247448, Acc: 0.931017\n",
      "Test Loss: 0.269762, Acc: 0.924400\n",
      "epoch 40\n",
      "**********\n",
      "[40/50] Loss: 0.245972, Acc: 0.934792\n",
      "[40/50] Loss: 0.246836, Acc: 0.933177\n",
      "[40/50] Loss: 0.245924, Acc: 0.933021\n",
      "[40/50] Loss: 0.245425, Acc: 0.932630\n",
      "[40/50] Loss: 0.243243, Acc: 0.933521\n",
      "[40/50] Loss: 0.246312, Acc: 0.932118\n",
      "Finish 40 epoch, Loss: 0.247503, Acc: 0.931867\n",
      "Test Loss: 0.272969, Acc: 0.923200\n",
      "epoch 41\n",
      "**********\n",
      "[41/50] Loss: 0.239738, Acc: 0.933438\n",
      "[41/50] Loss: 0.240457, Acc: 0.931198\n",
      "[41/50] Loss: 0.244573, Acc: 0.931389\n",
      "[41/50] Loss: 0.248502, Acc: 0.931146\n",
      "[41/50] Loss: 0.246988, Acc: 0.931750\n",
      "[41/50] Loss: 0.246285, Acc: 0.931510\n",
      "Finish 41 epoch, Loss: 0.247346, Acc: 0.931517\n",
      "Test Loss: 0.271042, Acc: 0.925500\n",
      "epoch 42\n",
      "**********\n",
      "[42/50] Loss: 0.250521, Acc: 0.933021\n",
      "[42/50] Loss: 0.248331, Acc: 0.934167\n",
      "[42/50] Loss: 0.247859, Acc: 0.933507\n",
      "[42/50] Loss: 0.249908, Acc: 0.932214\n",
      "[42/50] Loss: 0.247457, Acc: 0.932271\n",
      "[42/50] Loss: 0.247527, Acc: 0.932031\n",
      "Finish 42 epoch, Loss: 0.246847, Acc: 0.932233\n",
      "Test Loss: 0.269724, Acc: 0.925300\n",
      "epoch 43\n",
      "**********\n",
      "[43/50] Loss: 0.243297, Acc: 0.934271\n",
      "[43/50] Loss: 0.241910, Acc: 0.933594\n",
      "[43/50] Loss: 0.241032, Acc: 0.933333\n",
      "[43/50] Loss: 0.242815, Acc: 0.932240\n",
      "[43/50] Loss: 0.245870, Acc: 0.931687\n",
      "[43/50] Loss: 0.245015, Acc: 0.931840\n",
      "Finish 43 epoch, Loss: 0.246623, Acc: 0.931483\n",
      "Test Loss: 0.269971, Acc: 0.924700\n",
      "epoch 44\n",
      "**********\n",
      "[44/50] Loss: 0.237349, Acc: 0.931667\n",
      "[44/50] Loss: 0.243909, Acc: 0.931771\n",
      "[44/50] Loss: 0.243473, Acc: 0.933125\n",
      "[44/50] Loss: 0.247026, Acc: 0.931563\n",
      "[44/50] Loss: 0.247324, Acc: 0.931437\n",
      "[44/50] Loss: 0.246264, Acc: 0.931233\n",
      "Finish 44 epoch, Loss: 0.245884, Acc: 0.931167\n",
      "Test Loss: 0.269067, Acc: 0.926200\n",
      "epoch 45\n",
      "**********\n",
      "[45/50] Loss: 0.234765, Acc: 0.934271\n",
      "[45/50] Loss: 0.247495, Acc: 0.930573\n",
      "[45/50] Loss: 0.243924, Acc: 0.931354\n",
      "[45/50] Loss: 0.246270, Acc: 0.931120\n",
      "[45/50] Loss: 0.247301, Acc: 0.930979\n",
      "[45/50] Loss: 0.247202, Acc: 0.930938\n",
      "Finish 45 epoch, Loss: 0.245734, Acc: 0.931317\n",
      "Test Loss: 0.268808, Acc: 0.925400\n",
      "epoch 46\n",
      "**********\n",
      "[46/50] Loss: 0.243504, Acc: 0.933125\n",
      "[46/50] Loss: 0.239946, Acc: 0.933177\n",
      "[46/50] Loss: 0.246900, Acc: 0.931563\n",
      "[46/50] Loss: 0.248852, Acc: 0.931380\n",
      "[46/50] Loss: 0.248848, Acc: 0.931604\n",
      "[46/50] Loss: 0.245378, Acc: 0.932222\n",
      "Finish 46 epoch, Loss: 0.245560, Acc: 0.932183\n",
      "Test Loss: 0.271468, Acc: 0.924300\n",
      "epoch 47\n",
      "**********\n",
      "[47/50] Loss: 0.236108, Acc: 0.935208\n",
      "[47/50] Loss: 0.233255, Acc: 0.935521\n",
      "[47/50] Loss: 0.231615, Acc: 0.935521\n",
      "[47/50] Loss: 0.236508, Acc: 0.934141\n",
      "[47/50] Loss: 0.244181, Acc: 0.932813\n",
      "[47/50] Loss: 0.244484, Acc: 0.932656\n",
      "Finish 47 epoch, Loss: 0.245377, Acc: 0.932450\n",
      "Test Loss: 0.280876, Acc: 0.923700\n",
      "epoch 48\n",
      "**********\n",
      "[48/50] Loss: 0.243643, Acc: 0.934583\n",
      "[48/50] Loss: 0.246554, Acc: 0.931927\n",
      "[48/50] Loss: 0.242106, Acc: 0.933021\n",
      "[48/50] Loss: 0.243463, Acc: 0.932734\n",
      "[48/50] Loss: 0.243727, Acc: 0.932146\n",
      "[48/50] Loss: 0.244962, Acc: 0.932135\n",
      "Finish 48 epoch, Loss: 0.244884, Acc: 0.932150\n",
      "Test Loss: 0.272282, Acc: 0.923500\n",
      "epoch 49\n",
      "**********\n",
      "[49/50] Loss: 0.239294, Acc: 0.931667\n",
      "[49/50] Loss: 0.244168, Acc: 0.930729\n",
      "[49/50] Loss: 0.244848, Acc: 0.932153\n",
      "[49/50] Loss: 0.243331, Acc: 0.931693\n",
      "[49/50] Loss: 0.243101, Acc: 0.931958\n",
      "[49/50] Loss: 0.245113, Acc: 0.931580\n",
      "Finish 49 epoch, Loss: 0.244859, Acc: 0.931650\n",
      "Test Loss: 0.268207, Acc: 0.924900\n",
      "epoch 50\n",
      "**********\n",
      "[50/50] Loss: 0.243079, Acc: 0.932500\n",
      "[50/50] Loss: 0.239658, Acc: 0.932969\n",
      "[50/50] Loss: 0.243677, Acc: 0.932083\n",
      "[50/50] Loss: 0.243278, Acc: 0.931901\n",
      "[50/50] Loss: 0.244731, Acc: 0.931792\n",
      "[50/50] Loss: 0.244821, Acc: 0.931858\n",
      "Finish 50 epoch, Loss: 0.244484, Acc: 0.932017\n",
      "Test Loss: 0.275294, Acc: 0.923300\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoches):\n",
    "    print(f'epoch {epoch+1}')\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        # forward propagation\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum().float()\n",
    "        running_acc += num_correct\n",
    "        # backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 300 == 0:\n",
    "            print(f'[{epoch+1}/{num_epoches}] Loss: {running_loss/(batch_size*i):.6f}, Acc: {running_acc/(batch_size*i):.6f}')\n",
    "    print(f'Finish {epoch+1} epoch, Loss: {running_loss/(len(train_dataset)):.6f}, Acc: {running_acc/len(train_dataset):.6f}')\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum().float()\n",
    "        eval_acc += num_correct\n",
    "    print(f'Test Loss: {eval_loss/(len(test_dataset)):.6f}, Acc: {eval_acc/(len(test_dataset)):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'save/03-neural network.pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
