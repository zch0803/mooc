{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('save/conv_gan'):\n",
    "    os.mkdir('save/conv_gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    out = 0.5 * (x + 1)\n",
    "    out = out.clamp(0, 1)\n",
    "    out = out.reshape(-1, 1, 28, 28)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epoches = 100\n",
    "z_dimension = 100  # noise dimension\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # whether GPU is supportted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST('../_data/mnist', transform=img_transform)\n",
    "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5, padding=2), # batch, 32, 28, 28\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.AvgPool2d(2, stride=2), # batch, 32, 14, 14\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 5, padding=2), # batch, 64, 14, 14\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.AvgPool2d(2, stride=2) # batch, 64, 7, 7\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*7*7, 1024),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: batch, width, height, channel=1\n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, input_size, num_feature):\n",
    "        super(generator, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_feature) # batch, 3136=1x56x56\n",
    "        self.br = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.downsample1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 50, 3, stride=1, padding=1), # batch, 50, 56, 56\n",
    "            nn.BatchNorm2d(50),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.downsample2 = nn.Sequential(\n",
    "            nn.Conv2d(50, 25, 3, stride=1, padding=1), # batch, 25, 56, 56\n",
    "            nn.BatchNorm2d(25),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.downsample3 = nn.Sequential(\n",
    "            nn.Conv2d(25, 1, 2, stride=2), # batch, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 1, 56, 56)\n",
    "        x = self.br(x)\n",
    "        x = self.downsample1(x)\n",
    "        x = self.downsample2(x)\n",
    "        x = self.downsample3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator().to(device) # discriminator model\n",
    "G = generator(z_dimension, 3136).to(device) # generator model\n",
    "\n",
    "criterion = nn.BCELoss()  # binary cross entropy\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], d_loss: 0.004862, g_loss: 6.344368 D real: 0.997937, D fake: 0.002733\n",
      "Epoch [0/100], d_loss: 0.072482, g_loss: 3.796228 D real: 0.959111, D fake: 0.027240\n",
      "Epoch [0/100], d_loss: 0.270547, g_loss: 3.340040 D real: 0.830400, D fake: 0.022542\n",
      "Epoch [0/100], d_loss: 0.575651, g_loss: 2.782383 D real: 0.888074, D fake: 0.237495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], d_loss: 0.505719, g_loss: 1.531267 D real: 0.765558, D fake: 0.150167\n",
      "Epoch [1/100], d_loss: 0.414941, g_loss: 1.646160 D real: 0.866862, D fake: 0.178987\n",
      "Epoch [1/100], d_loss: 0.417752, g_loss: 1.508854 D real: 0.836492, D fake: 0.157988\n",
      "Epoch [1/100], d_loss: 0.761354, g_loss: 3.875142 D real: 0.633709, D fake: 0.026091\n",
      "Epoch [2/100], d_loss: 0.333925, g_loss: 2.182739 D real: 0.865069, D fake: 0.097720\n",
      "Epoch [2/100], d_loss: 0.334393, g_loss: 3.307405 D real: 0.913608, D fake: 0.169393\n",
      "Epoch [2/100], d_loss: 0.434161, g_loss: 3.434336 D real: 0.820223, D fake: 0.051994\n",
      "Epoch [2/100], d_loss: 0.432479, g_loss: 3.617238 D real: 0.959572, D fake: 0.260158\n",
      "Epoch [3/100], d_loss: 0.346676, g_loss: 1.696260 D real: 0.837161, D fake: 0.063617\n",
      "Epoch [3/100], d_loss: 0.388021, g_loss: 2.449858 D real: 0.897044, D fake: 0.151859\n",
      "Epoch [3/100], d_loss: 0.240741, g_loss: 3.794872 D real: 0.923281, D fake: 0.109866\n",
      "Epoch [3/100], d_loss: 0.373882, g_loss: 1.993526 D real: 0.887010, D fake: 0.155369\n",
      "Epoch [4/100], d_loss: 0.355581, g_loss: 2.822404 D real: 0.880899, D fake: 0.110101\n",
      "Epoch [4/100], d_loss: 0.421752, g_loss: 1.669975 D real: 0.808964, D fake: 0.055531\n",
      "Epoch [4/100], d_loss: 0.377253, g_loss: 2.890634 D real: 0.885931, D fake: 0.133719\n",
      "Epoch [4/100], d_loss: 0.365926, g_loss: 2.703544 D real: 0.865864, D fake: 0.113159\n",
      "Epoch [5/100], d_loss: 0.515863, g_loss: 2.366687 D real: 0.827391, D fake: 0.138009\n",
      "Epoch [5/100], d_loss: 0.452615, g_loss: 2.409673 D real: 0.907584, D fake: 0.214562\n",
      "Epoch [5/100], d_loss: 0.402933, g_loss: 1.736536 D real: 0.856328, D fake: 0.129430\n",
      "Epoch [5/100], d_loss: 0.409319, g_loss: 2.400341 D real: 0.863481, D fake: 0.152055\n",
      "Epoch [6/100], d_loss: 0.602993, g_loss: 3.130271 D real: 0.788854, D fake: 0.130180\n",
      "Epoch [6/100], d_loss: 0.602493, g_loss: 3.436517 D real: 0.924061, D fake: 0.321719\n",
      "Epoch [6/100], d_loss: 0.406524, g_loss: 2.549529 D real: 0.818552, D fake: 0.068707\n",
      "Epoch [6/100], d_loss: 0.342390, g_loss: 3.501309 D real: 0.869830, D fake: 0.080054\n",
      "Epoch [7/100], d_loss: 0.525233, g_loss: 1.532444 D real: 0.816242, D fake: 0.140745\n",
      "Epoch [7/100], d_loss: 0.357328, g_loss: 3.119783 D real: 0.872359, D fake: 0.110533\n",
      "Epoch [7/100], d_loss: 0.637274, g_loss: 3.746944 D real: 0.734295, D fake: 0.049539\n",
      "Epoch [7/100], d_loss: 0.653835, g_loss: 2.946851 D real: 0.755686, D fake: 0.048118\n",
      "Epoch [8/100], d_loss: 0.320501, g_loss: 2.843278 D real: 0.883201, D fake: 0.109924\n",
      "Epoch [8/100], d_loss: 0.367824, g_loss: 3.219366 D real: 0.841473, D fake: 0.083761\n",
      "Epoch [8/100], d_loss: 0.470434, g_loss: 2.469984 D real: 0.848851, D fake: 0.127049\n",
      "Epoch [8/100], d_loss: 0.506791, g_loss: 2.673367 D real: 0.892166, D fake: 0.242397\n",
      "Epoch [9/100], d_loss: 0.624112, g_loss: 3.124273 D real: 0.757493, D fake: 0.087356\n",
      "Epoch [9/100], d_loss: 0.547901, g_loss: 2.303222 D real: 0.767685, D fake: 0.100003\n",
      "Epoch [9/100], d_loss: 0.465722, g_loss: 3.126736 D real: 0.856596, D fake: 0.169167\n",
      "Epoch [9/100], d_loss: 0.515545, g_loss: 3.391825 D real: 0.867857, D fake: 0.211120\n",
      "Epoch [10/100], d_loss: 0.486285, g_loss: 3.304664 D real: 0.896302, D fake: 0.211316\n",
      "Epoch [10/100], d_loss: 0.561732, g_loss: 1.182304 D real: 0.851734, D fake: 0.226740\n",
      "Epoch [10/100], d_loss: 0.645583, g_loss: 2.111762 D real: 0.898681, D fake: 0.318272\n",
      "Epoch [10/100], d_loss: 0.518960, g_loss: 2.801123 D real: 0.885519, D fake: 0.239309\n",
      "Epoch [11/100], d_loss: 0.428845, g_loss: 2.933653 D real: 0.861297, D fake: 0.151782\n",
      "Epoch [11/100], d_loss: 0.460768, g_loss: 2.955403 D real: 0.818439, D fake: 0.120803\n",
      "Epoch [11/100], d_loss: 0.474526, g_loss: 3.526841 D real: 0.845894, D fake: 0.137671\n",
      "Epoch [11/100], d_loss: 0.548849, g_loss: 1.708434 D real: 0.804561, D fake: 0.146368\n",
      "Epoch [12/100], d_loss: 0.496048, g_loss: 2.209074 D real: 0.859594, D fake: 0.192178\n",
      "Epoch [12/100], d_loss: 0.540968, g_loss: 2.875163 D real: 0.863990, D fake: 0.202869\n",
      "Epoch [12/100], d_loss: 0.530476, g_loss: 1.944630 D real: 0.827244, D fake: 0.168650\n",
      "Epoch [12/100], d_loss: 0.556444, g_loss: 2.615973 D real: 0.835319, D fake: 0.155980\n",
      "Epoch [13/100], d_loss: 0.557143, g_loss: 2.400454 D real: 0.791100, D fake: 0.102320\n",
      "Epoch [13/100], d_loss: 0.540807, g_loss: 2.218333 D real: 0.846508, D fake: 0.203018\n",
      "Epoch [13/100], d_loss: 0.428380, g_loss: 2.189965 D real: 0.840394, D fake: 0.129913\n",
      "Epoch [13/100], d_loss: 0.502747, g_loss: 2.462645 D real: 0.813930, D fake: 0.116453\n",
      "Epoch [14/100], d_loss: 0.488615, g_loss: 3.004533 D real: 0.805526, D fake: 0.117690\n",
      "Epoch [14/100], d_loss: 0.541650, g_loss: 2.089209 D real: 0.872803, D fake: 0.230129\n",
      "Epoch [14/100], d_loss: 0.592308, g_loss: 2.054465 D real: 0.871102, D fake: 0.278343\n",
      "Epoch [14/100], d_loss: 0.709511, g_loss: 3.135648 D real: 0.854511, D fake: 0.305976\n",
      "Epoch [15/100], d_loss: 0.537359, g_loss: 1.741025 D real: 0.793448, D fake: 0.128127\n",
      "Epoch [15/100], d_loss: 0.459004, g_loss: 2.779011 D real: 0.827638, D fake: 0.134369\n",
      "Epoch [15/100], d_loss: 0.548271, g_loss: 2.939256 D real: 0.922011, D fake: 0.308728\n",
      "Epoch [15/100], d_loss: 0.550071, g_loss: 2.408720 D real: 0.836530, D fake: 0.190345\n",
      "Epoch [16/100], d_loss: 0.505062, g_loss: 2.655800 D real: 0.794867, D fake: 0.098547\n",
      "Epoch [16/100], d_loss: 0.406513, g_loss: 2.492125 D real: 0.864992, D fake: 0.155718\n",
      "Epoch [16/100], d_loss: 0.498858, g_loss: 2.788654 D real: 0.854231, D fake: 0.192717\n",
      "Epoch [16/100], d_loss: 0.618232, g_loss: 3.012632 D real: 0.775930, D fake: 0.112306\n",
      "Epoch [17/100], d_loss: 0.525755, g_loss: 2.332467 D real: 0.802002, D fake: 0.144492\n",
      "Epoch [17/100], d_loss: 0.667141, g_loss: 1.726012 D real: 0.734687, D fake: 0.080679\n",
      "Epoch [17/100], d_loss: 0.667317, g_loss: 2.153654 D real: 0.912098, D fake: 0.311691\n",
      "Epoch [17/100], d_loss: 0.676798, g_loss: 2.859782 D real: 0.794588, D fake: 0.192478\n",
      "Epoch [18/100], d_loss: 0.574638, g_loss: 2.555552 D real: 0.822484, D fake: 0.162696\n",
      "Epoch [18/100], d_loss: 0.615006, g_loss: 2.218822 D real: 0.778472, D fake: 0.148261\n",
      "Epoch [18/100], d_loss: 0.548010, g_loss: 2.245334 D real: 0.805343, D fake: 0.184898\n",
      "Epoch [18/100], d_loss: 0.546712, g_loss: 1.760490 D real: 0.797452, D fake: 0.136317\n",
      "Epoch [19/100], d_loss: 0.502962, g_loss: 2.185229 D real: 0.874428, D fake: 0.209417\n",
      "Epoch [19/100], d_loss: 0.679824, g_loss: 2.079446 D real: 0.714044, D fake: 0.071220\n",
      "Epoch [19/100], d_loss: 0.476466, g_loss: 2.418663 D real: 0.847686, D fake: 0.170861\n",
      "Epoch [19/100], d_loss: 0.506458, g_loss: 2.326497 D real: 0.832963, D fake: 0.183199\n",
      "Epoch [20/100], d_loss: 0.762388, g_loss: 2.771017 D real: 0.893103, D fake: 0.335720\n",
      "Epoch [20/100], d_loss: 0.497305, g_loss: 3.009608 D real: 0.846533, D fake: 0.196353\n",
      "Epoch [20/100], d_loss: 0.430299, g_loss: 3.892522 D real: 0.880650, D fake: 0.164448\n",
      "Epoch [20/100], d_loss: 0.581239, g_loss: 1.488473 D real: 0.773200, D fake: 0.111983\n",
      "Epoch [21/100], d_loss: 0.591628, g_loss: 2.228041 D real: 0.799230, D fake: 0.200067\n",
      "Epoch [21/100], d_loss: 0.586293, g_loss: 2.718472 D real: 0.778436, D fake: 0.096249\n",
      "Epoch [21/100], d_loss: 0.551887, g_loss: 2.706808 D real: 0.862963, D fake: 0.218016\n",
      "Epoch [21/100], d_loss: 0.689784, g_loss: 2.639503 D real: 0.876796, D fake: 0.264842\n",
      "Epoch [22/100], d_loss: 0.464697, g_loss: 2.951478 D real: 0.809975, D fake: 0.101846\n",
      "Epoch [22/100], d_loss: 0.541318, g_loss: 1.954693 D real: 0.879626, D fake: 0.251072\n",
      "Epoch [22/100], d_loss: 0.486873, g_loss: 2.627175 D real: 0.868333, D fake: 0.210112\n",
      "Epoch [22/100], d_loss: 0.489021, g_loss: 2.381252 D real: 0.860399, D fake: 0.176342\n",
      "Epoch [23/100], d_loss: 0.538871, g_loss: 2.043721 D real: 0.801397, D fake: 0.157414\n",
      "Epoch [23/100], d_loss: 0.559703, g_loss: 3.446578 D real: 0.825858, D fake: 0.168543\n",
      "Epoch [23/100], d_loss: 0.464178, g_loss: 2.770128 D real: 0.827057, D fake: 0.116811\n",
      "Epoch [23/100], d_loss: 0.498987, g_loss: 2.180227 D real: 0.817435, D fake: 0.144641\n",
      "Epoch [24/100], d_loss: 0.536185, g_loss: 2.212290 D real: 0.813718, D fake: 0.182056\n",
      "Epoch [24/100], d_loss: 0.525228, g_loss: 2.659198 D real: 0.852472, D fake: 0.192253\n",
      "Epoch [24/100], d_loss: 0.415831, g_loss: 2.204385 D real: 0.873263, D fake: 0.165169\n",
      "Epoch [24/100], d_loss: 0.641020, g_loss: 2.959757 D real: 0.929401, D fake: 0.338617\n",
      "Epoch [25/100], d_loss: 0.769040, g_loss: 2.996240 D real: 0.905528, D fake: 0.361343\n",
      "Epoch [25/100], d_loss: 0.532981, g_loss: 2.734540 D real: 0.788530, D fake: 0.089293\n",
      "Epoch [25/100], d_loss: 0.553569, g_loss: 2.119068 D real: 0.788839, D fake: 0.103226\n",
      "Epoch [25/100], d_loss: 0.464466, g_loss: 2.491857 D real: 0.830052, D fake: 0.142006\n",
      "Epoch [26/100], d_loss: 0.516278, g_loss: 2.042335 D real: 0.870800, D fake: 0.234945\n",
      "Epoch [26/100], d_loss: 0.511931, g_loss: 2.385489 D real: 0.822193, D fake: 0.161516\n",
      "Epoch [26/100], d_loss: 0.539876, g_loss: 1.909115 D real: 0.860646, D fake: 0.232524\n",
      "Epoch [26/100], d_loss: 0.552425, g_loss: 2.213586 D real: 0.812354, D fake: 0.152146\n",
      "Epoch [27/100], d_loss: 0.492671, g_loss: 2.401814 D real: 0.898411, D fake: 0.234921\n",
      "Epoch [27/100], d_loss: 0.601642, g_loss: 2.412920 D real: 0.870418, D fake: 0.276569\n",
      "Epoch [27/100], d_loss: 0.469922, g_loss: 2.655116 D real: 0.871307, D fake: 0.170535\n",
      "Epoch [27/100], d_loss: 0.445461, g_loss: 1.625787 D real: 0.880790, D fake: 0.205061\n",
      "Epoch [28/100], d_loss: 0.566429, g_loss: 2.765898 D real: 0.839159, D fake: 0.170318\n",
      "Epoch [28/100], d_loss: 0.447799, g_loss: 2.589820 D real: 0.837833, D fake: 0.127010\n",
      "Epoch [28/100], d_loss: 0.469779, g_loss: 2.313175 D real: 0.806529, D fake: 0.096315\n",
      "Epoch [28/100], d_loss: 0.581255, g_loss: 1.508201 D real: 0.839469, D fake: 0.206276\n",
      "Epoch [29/100], d_loss: 0.466290, g_loss: 2.877840 D real: 0.830468, D fake: 0.143783\n",
      "Epoch [29/100], d_loss: 0.388009, g_loss: 2.029599 D real: 0.869626, D fake: 0.144114\n",
      "Epoch [29/100], d_loss: 0.440129, g_loss: 2.200031 D real: 0.850913, D fake: 0.165279\n",
      "Epoch [29/100], d_loss: 0.405545, g_loss: 2.226924 D real: 0.882624, D fake: 0.179798\n",
      "Epoch [30/100], d_loss: 0.525855, g_loss: 2.840460 D real: 0.831533, D fake: 0.179701\n",
      "Epoch [30/100], d_loss: 0.504769, g_loss: 1.834994 D real: 0.815750, D fake: 0.163097\n",
      "Epoch [30/100], d_loss: 0.426013, g_loss: 3.158291 D real: 0.847059, D fake: 0.117334\n",
      "Epoch [30/100], d_loss: 0.573774, g_loss: 2.421237 D real: 0.775951, D fake: 0.134799\n",
      "Epoch [31/100], d_loss: 0.530120, g_loss: 2.369072 D real: 0.788271, D fake: 0.132182\n",
      "Epoch [31/100], d_loss: 0.440452, g_loss: 2.880048 D real: 0.872634, D fake: 0.174158\n",
      "Epoch [31/100], d_loss: 0.677645, g_loss: 2.458929 D real: 0.819136, D fake: 0.237438\n",
      "Epoch [31/100], d_loss: 0.479088, g_loss: 1.961452 D real: 0.866812, D fake: 0.150652\n",
      "Epoch [32/100], d_loss: 0.549869, g_loss: 3.231742 D real: 0.797438, D fake: 0.132745\n",
      "Epoch [32/100], d_loss: 0.493785, g_loss: 2.312263 D real: 0.811506, D fake: 0.110502\n",
      "Epoch [32/100], d_loss: 0.552725, g_loss: 1.765195 D real: 0.887341, D fake: 0.262779\n",
      "Epoch [32/100], d_loss: 0.614710, g_loss: 3.488054 D real: 0.801343, D fake: 0.139322\n",
      "Epoch [33/100], d_loss: 0.557880, g_loss: 3.623065 D real: 0.777483, D fake: 0.088681\n",
      "Epoch [33/100], d_loss: 0.456214, g_loss: 2.013703 D real: 0.840618, D fake: 0.143795\n",
      "Epoch [33/100], d_loss: 0.519629, g_loss: 2.631030 D real: 0.852230, D fake: 0.181323\n",
      "Epoch [33/100], d_loss: 0.641516, g_loss: 2.232733 D real: 0.797616, D fake: 0.184399\n",
      "Epoch [34/100], d_loss: 0.494888, g_loss: 2.302649 D real: 0.903527, D fake: 0.253782\n",
      "Epoch [34/100], d_loss: 0.511797, g_loss: 2.171967 D real: 0.820993, D fake: 0.153845\n",
      "Epoch [34/100], d_loss: 0.638589, g_loss: 3.169283 D real: 0.776032, D fake: 0.139343\n",
      "Epoch [34/100], d_loss: 0.554086, g_loss: 2.344951 D real: 0.849592, D fake: 0.182941\n",
      "Epoch [35/100], d_loss: 0.493963, g_loss: 2.152112 D real: 0.831723, D fake: 0.156243\n",
      "Epoch [35/100], d_loss: 0.437106, g_loss: 2.564439 D real: 0.881688, D fake: 0.172731\n",
      "Epoch [35/100], d_loss: 0.568606, g_loss: 2.832355 D real: 0.802428, D fake: 0.110202\n",
      "Epoch [35/100], d_loss: 0.490474, g_loss: 1.750121 D real: 0.892088, D fake: 0.228387\n",
      "Epoch [36/100], d_loss: 0.495675, g_loss: 2.867955 D real: 0.786720, D fake: 0.107296\n",
      "Epoch [36/100], d_loss: 0.454144, g_loss: 2.550600 D real: 0.854883, D fake: 0.166436\n",
      "Epoch [36/100], d_loss: 0.593364, g_loss: 2.816561 D real: 0.783664, D fake: 0.144494\n",
      "Epoch [36/100], d_loss: 0.437512, g_loss: 3.176244 D real: 0.935017, D fake: 0.221250\n",
      "Epoch [37/100], d_loss: 0.511323, g_loss: 2.016885 D real: 0.823763, D fake: 0.157590\n",
      "Epoch [37/100], d_loss: 0.494867, g_loss: 1.949778 D real: 0.826010, D fake: 0.105168\n",
      "Epoch [37/100], d_loss: 0.483928, g_loss: 2.143186 D real: 0.855867, D fake: 0.178588\n",
      "Epoch [37/100], d_loss: 0.493877, g_loss: 2.504474 D real: 0.844386, D fake: 0.154227\n",
      "Epoch [38/100], d_loss: 0.520635, g_loss: 2.336903 D real: 0.834184, D fake: 0.176016\n",
      "Epoch [38/100], d_loss: 0.476229, g_loss: 1.954380 D real: 0.827730, D fake: 0.129539\n",
      "Epoch [38/100], d_loss: 0.515895, g_loss: 3.068334 D real: 0.819623, D fake: 0.085040\n",
      "Epoch [38/100], d_loss: 0.484091, g_loss: 2.110327 D real: 0.851020, D fake: 0.185132\n",
      "Epoch [39/100], d_loss: 0.409705, g_loss: 3.065827 D real: 0.879665, D fake: 0.161091\n",
      "Epoch [39/100], d_loss: 0.527887, g_loss: 2.750814 D real: 0.831585, D fake: 0.143611\n",
      "Epoch [39/100], d_loss: 0.449666, g_loss: 2.831831 D real: 0.877823, D fake: 0.181695\n",
      "Epoch [39/100], d_loss: 0.594898, g_loss: 3.400890 D real: 0.849565, D fake: 0.209125\n",
      "Epoch [40/100], d_loss: 0.501482, g_loss: 2.298474 D real: 0.830748, D fake: 0.126190\n",
      "Epoch [40/100], d_loss: 0.478180, g_loss: 3.093690 D real: 0.888125, D fake: 0.233546\n",
      "Epoch [40/100], d_loss: 0.517950, g_loss: 2.080756 D real: 0.847594, D fake: 0.202222\n",
      "Epoch [40/100], d_loss: 0.534635, g_loss: 2.550039 D real: 0.797778, D fake: 0.106851\n",
      "Epoch [41/100], d_loss: 0.616775, g_loss: 3.468762 D real: 0.757862, D fake: 0.070988\n",
      "Epoch [41/100], d_loss: 0.378897, g_loss: 2.491623 D real: 0.891344, D fake: 0.148943\n",
      "Epoch [41/100], d_loss: 0.603272, g_loss: 2.075438 D real: 0.799897, D fake: 0.165843\n",
      "Epoch [41/100], d_loss: 0.494197, g_loss: 2.386907 D real: 0.872459, D fake: 0.206286\n",
      "Epoch [42/100], d_loss: 0.463432, g_loss: 2.238773 D real: 0.876369, D fake: 0.187503\n",
      "Epoch [42/100], d_loss: 0.498565, g_loss: 2.622422 D real: 0.881802, D fake: 0.233190\n",
      "Epoch [42/100], d_loss: 0.559151, g_loss: 1.883577 D real: 0.802395, D fake: 0.151598\n",
      "Epoch [42/100], d_loss: 0.379954, g_loss: 3.096651 D real: 0.935188, D fake: 0.200132\n",
      "Epoch [43/100], d_loss: 0.427058, g_loss: 2.454477 D real: 0.860146, D fake: 0.137239\n",
      "Epoch [43/100], d_loss: 0.490937, g_loss: 2.667197 D real: 0.855076, D fake: 0.163490\n",
      "Epoch [43/100], d_loss: 0.520988, g_loss: 2.808619 D real: 0.877290, D fake: 0.231547\n",
      "Epoch [43/100], d_loss: 0.397072, g_loss: 2.384128 D real: 0.857007, D fake: 0.134951\n",
      "Epoch [44/100], d_loss: 0.412469, g_loss: 2.732616 D real: 0.896603, D fake: 0.169500\n",
      "Epoch [44/100], d_loss: 0.429449, g_loss: 2.147894 D real: 0.863263, D fake: 0.160329\n",
      "Epoch [44/100], d_loss: 0.474450, g_loss: 3.103552 D real: 0.873712, D fake: 0.197307\n",
      "Epoch [44/100], d_loss: 0.475570, g_loss: 2.833749 D real: 0.875158, D fake: 0.197905\n",
      "Epoch [45/100], d_loss: 0.389644, g_loss: 2.765968 D real: 0.863611, D fake: 0.131034\n",
      "Epoch [45/100], d_loss: 0.444587, g_loss: 2.512173 D real: 0.911968, D fake: 0.211283\n",
      "Epoch [45/100], d_loss: 0.475448, g_loss: 2.501037 D real: 0.849823, D fake: 0.129399\n",
      "Epoch [45/100], d_loss: 0.590468, g_loss: 3.180738 D real: 0.853084, D fake: 0.185068\n",
      "Epoch [46/100], d_loss: 0.361460, g_loss: 2.441407 D real: 0.895619, D fake: 0.146687\n",
      "Epoch [46/100], d_loss: 0.763032, g_loss: 3.445711 D real: 0.726889, D fake: 0.043624\n",
      "Epoch [46/100], d_loss: 0.466519, g_loss: 2.058475 D real: 0.855943, D fake: 0.152533\n",
      "Epoch [46/100], d_loss: 0.513082, g_loss: 2.246725 D real: 0.921713, D fake: 0.244385\n",
      "Epoch [47/100], d_loss: 0.599190, g_loss: 1.879783 D real: 0.823317, D fake: 0.202708\n",
      "Epoch [47/100], d_loss: 0.416395, g_loss: 2.745371 D real: 0.861509, D fake: 0.141283\n",
      "Epoch [47/100], d_loss: 0.459482, g_loss: 2.556483 D real: 0.866494, D fake: 0.167692\n",
      "Epoch [47/100], d_loss: 0.355753, g_loss: 2.796442 D real: 0.866050, D fake: 0.099234\n",
      "Epoch [48/100], d_loss: 0.405907, g_loss: 3.099397 D real: 0.859012, D fake: 0.120927\n",
      "Epoch [48/100], d_loss: 0.432220, g_loss: 3.163149 D real: 0.902892, D fake: 0.205814\n",
      "Epoch [48/100], d_loss: 0.517489, g_loss: 3.410808 D real: 0.815912, D fake: 0.074438\n",
      "Epoch [48/100], d_loss: 0.412581, g_loss: 2.695867 D real: 0.858642, D fake: 0.126318\n",
      "Epoch [49/100], d_loss: 0.493767, g_loss: 1.873650 D real: 0.820449, D fake: 0.126638\n",
      "Epoch [49/100], d_loss: 0.433110, g_loss: 2.822157 D real: 0.865488, D fake: 0.139142\n",
      "Epoch [49/100], d_loss: 0.374742, g_loss: 3.376256 D real: 0.895595, D fake: 0.160575\n",
      "Epoch [49/100], d_loss: 0.401886, g_loss: 2.166108 D real: 0.847571, D fake: 0.119152\n",
      "Epoch [50/100], d_loss: 0.547535, g_loss: 2.737296 D real: 0.798668, D fake: 0.098484\n",
      "Epoch [50/100], d_loss: 0.416581, g_loss: 2.525153 D real: 0.864348, D fake: 0.136398\n",
      "Epoch [50/100], d_loss: 0.466189, g_loss: 2.464754 D real: 0.899203, D fake: 0.209057\n",
      "Epoch [50/100], d_loss: 0.495355, g_loss: 2.960937 D real: 0.845095, D fake: 0.160738\n",
      "Epoch [51/100], d_loss: 0.417245, g_loss: 2.071211 D real: 0.876994, D fake: 0.175168\n",
      "Epoch [51/100], d_loss: 0.389684, g_loss: 2.359648 D real: 0.877101, D fake: 0.134149\n",
      "Epoch [51/100], d_loss: 0.436014, g_loss: 3.478047 D real: 0.817321, D fake: 0.085229\n",
      "Epoch [51/100], d_loss: 0.483024, g_loss: 3.131435 D real: 0.811316, D fake: 0.079454\n",
      "Epoch [52/100], d_loss: 0.485021, g_loss: 2.470834 D real: 0.814134, D fake: 0.115401\n",
      "Epoch [52/100], d_loss: 0.492599, g_loss: 3.661632 D real: 0.824599, D fake: 0.119553\n",
      "Epoch [52/100], d_loss: 0.486309, g_loss: 2.403111 D real: 0.892112, D fake: 0.221126\n",
      "Epoch [52/100], d_loss: 0.549173, g_loss: 2.876602 D real: 0.793280, D fake: 0.111923\n",
      "Epoch [53/100], d_loss: 0.465537, g_loss: 2.451295 D real: 0.863403, D fake: 0.161604\n",
      "Epoch [53/100], d_loss: 0.447804, g_loss: 3.043376 D real: 0.822774, D fake: 0.092484\n",
      "Epoch [53/100], d_loss: 0.521684, g_loss: 2.628115 D real: 0.785562, D fake: 0.083628\n",
      "Epoch [53/100], d_loss: 0.396967, g_loss: 2.702983 D real: 0.849408, D fake: 0.122409\n",
      "Epoch [54/100], d_loss: 0.483478, g_loss: 3.388755 D real: 0.839583, D fake: 0.116387\n",
      "Epoch [54/100], d_loss: 0.482689, g_loss: 3.065155 D real: 0.855803, D fake: 0.175827\n",
      "Epoch [54/100], d_loss: 0.500025, g_loss: 2.358082 D real: 0.892173, D fake: 0.233164\n",
      "Epoch [54/100], d_loss: 0.441448, g_loss: 2.905770 D real: 0.833578, D fake: 0.105464\n",
      "Epoch [55/100], d_loss: 0.489620, g_loss: 3.029026 D real: 0.841558, D fake: 0.146520\n",
      "Epoch [55/100], d_loss: 0.428923, g_loss: 3.095949 D real: 0.851451, D fake: 0.093249\n",
      "Epoch [55/100], d_loss: 0.405467, g_loss: 2.399129 D real: 0.932481, D fake: 0.227829\n",
      "Epoch [55/100], d_loss: 0.462019, g_loss: 2.981615 D real: 0.903893, D fake: 0.224868\n",
      "Epoch [56/100], d_loss: 0.350632, g_loss: 3.688966 D real: 0.868548, D fake: 0.090000\n",
      "Epoch [56/100], d_loss: 0.401258, g_loss: 2.279786 D real: 0.882335, D fake: 0.165541\n",
      "Epoch [56/100], d_loss: 0.470144, g_loss: 2.707304 D real: 0.909476, D fake: 0.239026\n",
      "Epoch [56/100], d_loss: 0.439069, g_loss: 2.653886 D real: 0.837034, D fake: 0.119352\n",
      "Epoch [57/100], d_loss: 0.403873, g_loss: 2.608125 D real: 0.884810, D fake: 0.155452\n",
      "Epoch [57/100], d_loss: 0.497250, g_loss: 2.672256 D real: 0.831212, D fake: 0.120458\n",
      "Epoch [57/100], d_loss: 0.449075, g_loss: 2.517754 D real: 0.885208, D fake: 0.179426\n",
      "Epoch [57/100], d_loss: 0.385801, g_loss: 3.300907 D real: 0.876089, D fake: 0.114933\n",
      "Epoch [58/100], d_loss: 0.442726, g_loss: 2.700909 D real: 0.915462, D fake: 0.216379\n",
      "Epoch [58/100], d_loss: 0.518043, g_loss: 2.390239 D real: 0.781236, D fake: 0.066164\n",
      "Epoch [58/100], d_loss: 0.423397, g_loss: 3.326276 D real: 0.838354, D fake: 0.092540\n",
      "Epoch [58/100], d_loss: 0.422436, g_loss: 2.924572 D real: 0.862850, D fake: 0.104334\n",
      "Epoch [59/100], d_loss: 0.441661, g_loss: 2.813338 D real: 0.823401, D fake: 0.084564\n",
      "Epoch [59/100], d_loss: 0.421225, g_loss: 2.640242 D real: 0.922154, D fake: 0.220220\n",
      "Epoch [59/100], d_loss: 0.371609, g_loss: 2.444116 D real: 0.855204, D fake: 0.090454\n",
      "Epoch [59/100], d_loss: 0.469889, g_loss: 3.020793 D real: 0.826841, D fake: 0.095983\n",
      "Epoch [60/100], d_loss: 0.340907, g_loss: 3.085562 D real: 0.882924, D fake: 0.128432\n",
      "Epoch [60/100], d_loss: 0.436324, g_loss: 3.452308 D real: 0.828257, D fake: 0.078988\n",
      "Epoch [60/100], d_loss: 0.355407, g_loss: 2.447395 D real: 0.900705, D fake: 0.149653\n",
      "Epoch [60/100], d_loss: 0.476882, g_loss: 2.830051 D real: 0.846264, D fake: 0.111414\n",
      "Epoch [61/100], d_loss: 0.423073, g_loss: 2.748143 D real: 0.848353, D fake: 0.097915\n",
      "Epoch [61/100], d_loss: 0.422321, g_loss: 2.941806 D real: 0.903996, D fake: 0.176231\n",
      "Epoch [61/100], d_loss: 0.343805, g_loss: 3.537978 D real: 0.870445, D fake: 0.082439\n",
      "Epoch [61/100], d_loss: 0.494899, g_loss: 2.845627 D real: 0.863065, D fake: 0.164477\n",
      "Epoch [62/100], d_loss: 0.367028, g_loss: 2.568029 D real: 0.901628, D fake: 0.165691\n",
      "Epoch [62/100], d_loss: 0.404670, g_loss: 3.039804 D real: 0.851483, D fake: 0.093312\n",
      "Epoch [62/100], d_loss: 0.428306, g_loss: 3.603339 D real: 0.841744, D fake: 0.078296\n",
      "Epoch [62/100], d_loss: 0.397469, g_loss: 3.686574 D real: 0.865455, D fake: 0.098447\n",
      "Epoch [63/100], d_loss: 0.419566, g_loss: 1.975828 D real: 0.894553, D fake: 0.153773\n",
      "Epoch [63/100], d_loss: 0.417618, g_loss: 3.758316 D real: 0.872312, D fake: 0.126653\n",
      "Epoch [63/100], d_loss: 0.416157, g_loss: 2.691473 D real: 0.868076, D fake: 0.146806\n",
      "Epoch [63/100], d_loss: 0.372806, g_loss: 2.784595 D real: 0.863984, D fake: 0.092353\n",
      "Epoch [64/100], d_loss: 0.524253, g_loss: 2.571208 D real: 0.808808, D fake: 0.096162\n",
      "Epoch [64/100], d_loss: 0.395159, g_loss: 2.953282 D real: 0.874147, D fake: 0.122848\n",
      "Epoch [64/100], d_loss: 0.383691, g_loss: 2.676210 D real: 0.879119, D fake: 0.117974\n",
      "Epoch [64/100], d_loss: 0.441446, g_loss: 2.629950 D real: 0.877693, D fake: 0.159990\n",
      "Epoch [65/100], d_loss: 0.416871, g_loss: 2.643263 D real: 0.858497, D fake: 0.132205\n",
      "Epoch [65/100], d_loss: 0.500449, g_loss: 2.787197 D real: 0.897700, D fake: 0.212358\n",
      "Epoch [65/100], d_loss: 0.477460, g_loss: 3.878820 D real: 0.841073, D fake: 0.098322\n",
      "Epoch [65/100], d_loss: 0.355625, g_loss: 2.877229 D real: 0.877805, D fake: 0.089710\n",
      "Epoch [66/100], d_loss: 0.443275, g_loss: 2.823916 D real: 0.888056, D fake: 0.182432\n",
      "Epoch [66/100], d_loss: 0.557451, g_loss: 3.001704 D real: 0.815474, D fake: 0.112543\n",
      "Epoch [66/100], d_loss: 0.384509, g_loss: 2.954137 D real: 0.856266, D fake: 0.109253\n",
      "Epoch [66/100], d_loss: 0.356393, g_loss: 3.259537 D real: 0.888720, D fake: 0.136377\n",
      "Epoch [67/100], d_loss: 0.371976, g_loss: 2.664603 D real: 0.916061, D fake: 0.163387\n",
      "Epoch [67/100], d_loss: 0.334832, g_loss: 3.199663 D real: 0.864462, D fake: 0.054322\n",
      "Epoch [67/100], d_loss: 0.423963, g_loss: 3.438754 D real: 0.844542, D fake: 0.069145\n",
      "Epoch [67/100], d_loss: 0.438870, g_loss: 2.701678 D real: 0.867923, D fake: 0.147057\n",
      "Epoch [68/100], d_loss: 0.410568, g_loss: 2.708226 D real: 0.880460, D fake: 0.156978\n",
      "Epoch [68/100], d_loss: 0.416360, g_loss: 2.059803 D real: 0.877522, D fake: 0.148149\n",
      "Epoch [68/100], d_loss: 0.344632, g_loss: 1.869969 D real: 0.906286, D fake: 0.155989\n",
      "Epoch [68/100], d_loss: 0.452789, g_loss: 2.318975 D real: 0.908858, D fake: 0.210914\n",
      "Epoch [69/100], d_loss: 0.340935, g_loss: 3.247764 D real: 0.879868, D fake: 0.089389\n",
      "Epoch [69/100], d_loss: 0.495691, g_loss: 2.340878 D real: 0.884805, D fake: 0.192632\n",
      "Epoch [69/100], d_loss: 0.367418, g_loss: 3.026844 D real: 0.891434, D fake: 0.132104\n",
      "Epoch [69/100], d_loss: 0.352501, g_loss: 3.381147 D real: 0.874603, D fake: 0.062972\n",
      "Epoch [70/100], d_loss: 0.389081, g_loss: 2.275409 D real: 0.911182, D fake: 0.178570\n",
      "Epoch [70/100], d_loss: 0.389000, g_loss: 2.464228 D real: 0.845815, D fake: 0.074801\n",
      "Epoch [70/100], d_loss: 0.420370, g_loss: 2.933141 D real: 0.860231, D fake: 0.115717\n",
      "Epoch [70/100], d_loss: 0.454970, g_loss: 2.347214 D real: 0.911224, D fake: 0.179682\n",
      "Epoch [71/100], d_loss: 0.386584, g_loss: 2.642905 D real: 0.875994, D fake: 0.094045\n",
      "Epoch [71/100], d_loss: 0.403692, g_loss: 3.059021 D real: 0.860652, D fake: 0.103459\n",
      "Epoch [71/100], d_loss: 0.465680, g_loss: 2.590492 D real: 0.846390, D fake: 0.128785\n",
      "Epoch [71/100], d_loss: 0.358256, g_loss: 2.168245 D real: 0.911096, D fake: 0.151040\n",
      "Epoch [72/100], d_loss: 0.364777, g_loss: 2.288791 D real: 0.872150, D fake: 0.090105\n",
      "Epoch [72/100], d_loss: 0.294314, g_loss: 3.101162 D real: 0.927539, D fake: 0.138539\n",
      "Epoch [72/100], d_loss: 0.342592, g_loss: 2.329238 D real: 0.939948, D fake: 0.188687\n",
      "Epoch [72/100], d_loss: 0.384494, g_loss: 3.412239 D real: 0.867934, D fake: 0.071976\n",
      "Epoch [73/100], d_loss: 0.428983, g_loss: 3.564099 D real: 0.836758, D fake: 0.083280\n",
      "Epoch [73/100], d_loss: 0.330117, g_loss: 3.903735 D real: 0.897346, D fake: 0.120464\n",
      "Epoch [73/100], d_loss: 0.411807, g_loss: 2.668876 D real: 0.889956, D fake: 0.122592\n",
      "Epoch [73/100], d_loss: 0.389269, g_loss: 3.045209 D real: 0.903722, D fake: 0.174969\n",
      "Epoch [74/100], d_loss: 0.412597, g_loss: 2.727405 D real: 0.874423, D fake: 0.100469\n",
      "Epoch [74/100], d_loss: 0.408046, g_loss: 3.727136 D real: 0.862464, D fake: 0.062178\n",
      "Epoch [74/100], d_loss: 0.237247, g_loss: 3.517906 D real: 0.904609, D fake: 0.070032\n",
      "Epoch [74/100], d_loss: 0.267588, g_loss: 3.294507 D real: 0.933159, D fake: 0.105244\n",
      "Epoch [75/100], d_loss: 0.402968, g_loss: 3.453042 D real: 0.857832, D fake: 0.086007\n",
      "Epoch [75/100], d_loss: 0.351985, g_loss: 3.308759 D real: 0.892208, D fake: 0.118579\n",
      "Epoch [75/100], d_loss: 0.407816, g_loss: 2.571815 D real: 0.844108, D fake: 0.099221\n",
      "Epoch [75/100], d_loss: 0.415501, g_loss: 2.819182 D real: 0.891430, D fake: 0.152362\n",
      "Epoch [76/100], d_loss: 0.326022, g_loss: 2.440834 D real: 0.907255, D fake: 0.131973\n",
      "Epoch [76/100], d_loss: 0.373127, g_loss: 2.935513 D real: 0.873178, D fake: 0.100526\n",
      "Epoch [76/100], d_loss: 0.440530, g_loss: 2.548710 D real: 0.864805, D fake: 0.144708\n",
      "Epoch [76/100], d_loss: 0.441937, g_loss: 2.929386 D real: 0.835281, D fake: 0.045779\n",
      "Epoch [77/100], d_loss: 0.308541, g_loss: 3.334946 D real: 0.917161, D fake: 0.126533\n",
      "Epoch [77/100], d_loss: 0.434762, g_loss: 3.543342 D real: 0.815671, D fake: 0.042974\n",
      "Epoch [77/100], d_loss: 0.323740, g_loss: 3.079310 D real: 0.895182, D fake: 0.109500\n",
      "Epoch [77/100], d_loss: 0.469358, g_loss: 3.033779 D real: 0.851295, D fake: 0.102887\n",
      "Epoch [78/100], d_loss: 0.299899, g_loss: 3.570238 D real: 0.888994, D fake: 0.078269\n",
      "Epoch [78/100], d_loss: 0.425259, g_loss: 2.542191 D real: 0.901478, D fake: 0.189917\n",
      "Epoch [78/100], d_loss: 0.300764, g_loss: 2.971245 D real: 0.951207, D fake: 0.166456\n",
      "Epoch [78/100], d_loss: 0.321872, g_loss: 2.776848 D real: 0.936243, D fake: 0.150932\n",
      "Epoch [79/100], d_loss: 0.371465, g_loss: 3.573451 D real: 0.889361, D fake: 0.127780\n",
      "Epoch [79/100], d_loss: 0.364019, g_loss: 2.866090 D real: 0.880738, D fake: 0.119659\n",
      "Epoch [79/100], d_loss: 0.314277, g_loss: 3.342460 D real: 0.919309, D fake: 0.120260\n",
      "Epoch [79/100], d_loss: 0.344286, g_loss: 2.204981 D real: 0.901006, D fake: 0.147103\n",
      "Epoch [80/100], d_loss: 0.280068, g_loss: 3.105402 D real: 0.908635, D fake: 0.091751\n",
      "Epoch [80/100], d_loss: 0.418538, g_loss: 2.988853 D real: 0.823360, D fake: 0.083682\n",
      "Epoch [80/100], d_loss: 0.470000, g_loss: 3.309345 D real: 0.829673, D fake: 0.083678\n",
      "Epoch [80/100], d_loss: 0.324310, g_loss: 3.377767 D real: 0.922157, D fake: 0.147002\n",
      "Epoch [81/100], d_loss: 0.363661, g_loss: 3.307692 D real: 0.876782, D fake: 0.110051\n",
      "Epoch [81/100], d_loss: 0.479395, g_loss: 3.453414 D real: 0.807119, D fake: 0.063003\n",
      "Epoch [81/100], d_loss: 0.347696, g_loss: 3.243602 D real: 0.890488, D fake: 0.114591\n",
      "Epoch [81/100], d_loss: 0.359921, g_loss: 2.459222 D real: 0.901125, D fake: 0.150221\n",
      "Epoch [82/100], d_loss: 0.260687, g_loss: 4.020375 D real: 0.896837, D fake: 0.057097\n",
      "Epoch [82/100], d_loss: 0.383681, g_loss: 2.756265 D real: 0.870353, D fake: 0.112830\n",
      "Epoch [82/100], d_loss: 0.219696, g_loss: 3.064010 D real: 0.919819, D fake: 0.079441\n",
      "Epoch [82/100], d_loss: 0.486003, g_loss: 3.188731 D real: 0.896027, D fake: 0.216911\n",
      "Epoch [83/100], d_loss: 0.348343, g_loss: 2.990091 D real: 0.868394, D fake: 0.079816\n",
      "Epoch [83/100], d_loss: 0.339764, g_loss: 3.008368 D real: 0.887471, D fake: 0.088397\n",
      "Epoch [83/100], d_loss: 0.328213, g_loss: 3.247025 D real: 0.918480, D fake: 0.139307\n",
      "Epoch [83/100], d_loss: 0.335710, g_loss: 2.917177 D real: 0.893676, D fake: 0.132832\n",
      "Epoch [84/100], d_loss: 0.283063, g_loss: 2.720494 D real: 0.946487, D fake: 0.150161\n",
      "Epoch [84/100], d_loss: 0.369429, g_loss: 2.754200 D real: 0.864842, D fake: 0.094810\n",
      "Epoch [84/100], d_loss: 0.295775, g_loss: 3.267670 D real: 0.933700, D fake: 0.140926\n",
      "Epoch [84/100], d_loss: 0.422453, g_loss: 3.054929 D real: 0.852307, D fake: 0.090960\n",
      "Epoch [85/100], d_loss: 0.410694, g_loss: 2.697833 D real: 0.897027, D fake: 0.140543\n",
      "Epoch [85/100], d_loss: 0.439595, g_loss: 3.021712 D real: 0.848714, D fake: 0.068285\n",
      "Epoch [85/100], d_loss: 0.383952, g_loss: 2.677449 D real: 0.890520, D fake: 0.100649\n",
      "Epoch [85/100], d_loss: 0.380162, g_loss: 3.117158 D real: 0.909676, D fake: 0.149509\n",
      "Epoch [86/100], d_loss: 0.380049, g_loss: 2.164547 D real: 0.917422, D fake: 0.192199\n",
      "Epoch [86/100], d_loss: 0.396154, g_loss: 3.084520 D real: 0.912340, D fake: 0.136401\n",
      "Epoch [86/100], d_loss: 0.387934, g_loss: 3.906317 D real: 0.891058, D fake: 0.091866\n",
      "Epoch [86/100], d_loss: 0.372737, g_loss: 2.673076 D real: 0.932397, D fake: 0.192590\n",
      "Epoch [87/100], d_loss: 0.360420, g_loss: 3.097345 D real: 0.944712, D fake: 0.204726\n",
      "Epoch [87/100], d_loss: 0.330100, g_loss: 2.439989 D real: 0.887297, D fake: 0.081485\n",
      "Epoch [87/100], d_loss: 0.452788, g_loss: 3.894490 D real: 0.810467, D fake: 0.032430\n",
      "Epoch [87/100], d_loss: 0.380609, g_loss: 2.740585 D real: 0.864784, D fake: 0.107224\n",
      "Epoch [88/100], d_loss: 0.261896, g_loss: 3.658031 D real: 0.933609, D fake: 0.116851\n",
      "Epoch [88/100], d_loss: 0.320051, g_loss: 2.913769 D real: 0.913804, D fake: 0.137603\n",
      "Epoch [88/100], d_loss: 0.538561, g_loss: 4.730106 D real: 0.797191, D fake: 0.019972\n",
      "Epoch [88/100], d_loss: 0.309382, g_loss: 3.329275 D real: 0.919561, D fake: 0.121379\n",
      "Epoch [89/100], d_loss: 0.382586, g_loss: 3.047177 D real: 0.914772, D fake: 0.186299\n",
      "Epoch [89/100], d_loss: 0.358552, g_loss: 2.714333 D real: 0.912690, D fake: 0.131904\n",
      "Epoch [89/100], d_loss: 0.371882, g_loss: 3.467903 D real: 0.900609, D fake: 0.149671\n",
      "Epoch [89/100], d_loss: 0.255845, g_loss: 2.819205 D real: 0.911057, D fake: 0.072672\n",
      "Epoch [90/100], d_loss: 0.265656, g_loss: 2.581357 D real: 0.912288, D fake: 0.103870\n",
      "Epoch [90/100], d_loss: 0.258981, g_loss: 3.581628 D real: 0.917672, D fake: 0.079884\n",
      "Epoch [90/100], d_loss: 0.240967, g_loss: 3.025683 D real: 0.937905, D fake: 0.118844\n",
      "Epoch [90/100], d_loss: 0.312966, g_loss: 3.367345 D real: 0.919179, D fake: 0.141655\n",
      "Epoch [91/100], d_loss: 0.322003, g_loss: 2.861396 D real: 0.894088, D fake: 0.102646\n",
      "Epoch [91/100], d_loss: 0.270931, g_loss: 4.489072 D real: 0.915176, D fake: 0.082614\n",
      "Epoch [91/100], d_loss: 0.381536, g_loss: 3.938556 D real: 0.882005, D fake: 0.086699\n",
      "Epoch [91/100], d_loss: 0.414927, g_loss: 3.403461 D real: 0.854028, D fake: 0.060102\n",
      "Epoch [92/100], d_loss: 0.392547, g_loss: 3.079743 D real: 0.856698, D fake: 0.093817\n",
      "Epoch [92/100], d_loss: 0.278408, g_loss: 2.849698 D real: 0.911958, D fake: 0.088735\n",
      "Epoch [92/100], d_loss: 0.311360, g_loss: 2.788810 D real: 0.889212, D fake: 0.082071\n",
      "Epoch [92/100], d_loss: 0.369293, g_loss: 3.344198 D real: 0.866777, D fake: 0.080397\n",
      "Epoch [93/100], d_loss: 0.302593, g_loss: 3.051402 D real: 0.887743, D fake: 0.080254\n",
      "Epoch [93/100], d_loss: 0.457817, g_loss: 3.417902 D real: 0.870347, D fake: 0.164935\n",
      "Epoch [93/100], d_loss: 0.306257, g_loss: 3.684515 D real: 0.879586, D fake: 0.057723\n",
      "Epoch [93/100], d_loss: 0.320215, g_loss: 2.773048 D real: 0.898304, D fake: 0.117024\n",
      "Epoch [94/100], d_loss: 0.191034, g_loss: 3.941847 D real: 0.947413, D fake: 0.093833\n",
      "Epoch [94/100], d_loss: 0.304608, g_loss: 2.835015 D real: 0.906897, D fake: 0.120534\n",
      "Epoch [94/100], d_loss: 0.369585, g_loss: 3.282312 D real: 0.870248, D fake: 0.088853\n",
      "Epoch [94/100], d_loss: 0.255756, g_loss: 4.729012 D real: 0.891321, D fake: 0.036058\n",
      "Epoch [95/100], d_loss: 0.318111, g_loss: 4.041698 D real: 0.901618, D fake: 0.101588\n",
      "Epoch [95/100], d_loss: 0.347165, g_loss: 4.384539 D real: 0.877924, D fake: 0.058742\n",
      "Epoch [95/100], d_loss: 0.348990, g_loss: 3.553415 D real: 0.872771, D fake: 0.041545\n",
      "Epoch [95/100], d_loss: 0.421620, g_loss: 3.476484 D real: 0.897034, D fake: 0.135391\n",
      "Epoch [96/100], d_loss: 0.342324, g_loss: 3.302138 D real: 0.876344, D fake: 0.064131\n",
      "Epoch [96/100], d_loss: 0.347139, g_loss: 4.651311 D real: 0.869165, D fake: 0.028248\n",
      "Epoch [96/100], d_loss: 0.269958, g_loss: 4.277403 D real: 0.893348, D fake: 0.046637\n",
      "Epoch [96/100], d_loss: 0.484308, g_loss: 3.763008 D real: 0.838985, D fake: 0.077211\n",
      "Epoch [97/100], d_loss: 0.357831, g_loss: 3.227148 D real: 0.912083, D fake: 0.140540\n",
      "Epoch [97/100], d_loss: 0.286427, g_loss: 3.510118 D real: 0.929963, D fake: 0.122688\n",
      "Epoch [97/100], d_loss: 0.317587, g_loss: 3.530977 D real: 0.911414, D fake: 0.112435\n",
      "Epoch [97/100], d_loss: 0.267987, g_loss: 3.170931 D real: 0.933423, D fake: 0.125934\n",
      "Epoch [98/100], d_loss: 0.358333, g_loss: 3.092414 D real: 0.882050, D fake: 0.101696\n",
      "Epoch [98/100], d_loss: 0.195725, g_loss: 3.076216 D real: 0.936571, D fake: 0.081353\n",
      "Epoch [98/100], d_loss: 0.279319, g_loss: 3.820379 D real: 0.893656, D fake: 0.040481\n",
      "Epoch [98/100], d_loss: 0.298054, g_loss: 3.418992 D real: 0.890472, D fake: 0.061265\n",
      "Epoch [99/100], d_loss: 0.344888, g_loss: 2.886207 D real: 0.913035, D fake: 0.138218\n",
      "Epoch [99/100], d_loss: 0.327713, g_loss: 2.776423 D real: 0.876876, D fake: 0.079532\n",
      "Epoch [99/100], d_loss: 0.237928, g_loss: 4.116671 D real: 0.908478, D fake: 0.039182\n",
      "Epoch [99/100], d_loss: 0.267221, g_loss: 3.825263 D real: 0.903637, D fake: 0.060596\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(num_epoches):\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # =================train discriminator\n",
    "        real_img = img.to(device)\n",
    "        real_label = torch.ones(num_img).to(device)\n",
    "        fake_label = torch.zeros(num_img).to(device)\n",
    "\n",
    "        # compute loss of real_img\n",
    "        real_out = D(real_img)\n",
    "        d_loss_real = criterion(real_out, real_label)\n",
    "        real_scores = real_out  # closer to 1 means better\n",
    "\n",
    "        # compute loss of fake_img\n",
    "        z = torch.randn(num_img, z_dimension).to(device)\n",
    "        fake_img = G(z)\n",
    "        fake_out = D(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out  # closer to 0 means better\n",
    "\n",
    "        # bp and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # ===============train generator\n",
    "        # compute loss of fake_img\n",
    "        z = torch.randn(num_img, z_dimension).to(device)\n",
    "        fake_img = G(z)\n",
    "        output = D(fake_img)\n",
    "        g_loss = criterion(output, real_label)\n",
    "\n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epoches}], d_loss: {d_loss:.6f}, g_loss: {g_loss:.6f} '\n",
    "                  f'D real: {real_scores.mean():.6f}, D fake: {fake_scores.mean():.6f}')\n",
    "\n",
    "    if epoch == 0:\n",
    "        real_images = to_img(real_img)\n",
    "        save_image(real_images, 'save/conv_gan/real_images.png')\n",
    "\n",
    "    fake_images = to_img(fake_img)\n",
    "    save_image(fake_images, f'save/conv_gan/fake_images-{epoch+1:0>2}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), 'save/conv_gan/generator.pytorch')\n",
    "torch.save(D.state_dict(), 'save/conv_gan/discriminator.pytorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
